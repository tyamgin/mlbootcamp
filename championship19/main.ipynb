{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run cv.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_features = pd.read_pickle(output_path + '/train_text_features9')\n",
    "test_texts_features = pd.read_pickle(output_path + '/test_text_features9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_features['positivity'] = pd.read_pickle(output_path + '/positivity_train2').positivity\n",
    "test_texts_features['positivity'] = pd.read_pickle(output_path + '/positivity_test2').positivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_features.drop('embedding', 1, inplace=True)\n",
    "test_texts_features.drop('embedding', 1, inplace=True)\n",
    "#train_texts_features['embedding_lgb'] = pd.read_pickle(output_path + '/train_30_2_svd').embeddings\n",
    "#test_texts_features['embedding_lgb'] = pd.read_pickle(output_path + '/test_30_2_svd').embeddings\n",
    "train_texts_features['embedding_keras'] = pd.read_pickle(output_path + '/train__80__svd').embeddings\n",
    "test_texts_features['embedding_keras'] = pd.read_pickle(output_path + '/test__80__svd').embeddings\n",
    "\n",
    "#train_80_1_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_features['embedding'] = pd.read_pickle(output_path + '/train_100_embs').embeddings\n",
    "test_texts_features['embedding'] = pd.read_pickle(output_path + '/test_100_embs').embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_clusters3_15 = pd.read_pickle(output_path + '/assigned_clusters3_15').assigned_clusters3_15\n",
    "train_texts_features['assigned_clusters'] = assigned_clusters3_15[0:train_texts_features.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(output_path + '/train_data')\n",
    "test_data = pd.read_pickle(output_path + '/test_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = pd.concat((train_data, test_data), sort=False)[['metadata_ownerId', 'objectId']] \\\n",
    "    .groupby('metadata_ownerId').agg({'objectId': 'count'})\n",
    "stat.rename(columns={'objectId': 'owner_count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat3 = pd.concat((train_data, test_data), sort=False)[['objectId', 'instanceId_userId']] \\\n",
    "    .groupby('instanceId_userId').agg({'objectId': 'count'})\n",
    "stat3.rename(columns={'objectId': 'user_count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stat2 = pd.concat((train_data, test_data), sort=False)[['objectId', 'instanceId_userId']] \\\n",
    "#    .groupby('objectId').agg({'instanceId_userId': 'count'})\n",
    "#stat2.rename(columns={'instanceId_userId': 'object_count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.join(stat, how='left', on='metadata_ownerId')\n",
    "#train_data = train_data.join(stat2, how='left', on='metadata_ownerId')\n",
    "train_data = train_data.join(stat3, how='left', on='instanceId_userId')\n",
    "train_data = train_data.join(train_texts_features.set_index('objectId'), how='inner', on='objectId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.join(stat, how='left', on='metadata_ownerId')\n",
    "#test_data = test_data.join(stat2, how='left', on='metadata_ownerId')\n",
    "test_data = test_data.join(stat3, how='left', on='instanceId_userId')\n",
    "test_data = test_data.join(test_texts_features.set_index('objectId'), how='inner', on='objectId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq = train_data[['instanceId_userId', 'objectId', 'audit_timestamp']].groupby(['instanceId_userId', 'objectId']).count()\n",
    "qq.rename(columns={'audit_timestamp': 'edits_count'}, inplace=True)\n",
    "train_data = train_data.join(qq, how='left', on=['instanceId_userId', 'objectId'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq = test_data[['instanceId_userId', 'objectId', 'audit_timestamp']].groupby(['instanceId_userId', 'objectId']).count()\n",
    "qq.rename(columns={'audit_timestamp': 'edits_count'}, inplace=True)\n",
    "test_data = test_data.join(qq, how='left', on=['instanceId_userId', 'objectId'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LgbModel(MyModel):\n",
    "    def get_X(self, data):\n",
    "        X = super().get_X(data)\n",
    "        ###!!!!!!\n",
    "        X.drop([c for c in X.columns if c.startswith('embedding') and not c.startswith('embedding_keras')], 1, inplace=True)\n",
    "        X.drop(['end', 'is_ru'], 1, inplace=True)\n",
    "        return X\n",
    "    def fit(self, data):\n",
    "        #data = data.drop_duplicates(['instanceId_userId', 'objectId'], keep='last')\n",
    "        \n",
    "        #owner_stat = data[['metadata_ownerId', 'label']].groupby('metadata_ownerId').mean()\n",
    "        #owner_stat.rename(columns={'label': 'owner_mean_label'}, inplace=True)\n",
    "        #self.owner_stat = owner_stat\n",
    "        #data = data.join(owner_stat, how='left', on='metadata_ownerId')\n",
    "        '''\n",
    "        grp = data[['instanceId_userId', 'label']].groupby('instanceId_userId')\n",
    "        self.owner_stat = grp.sum() / (grp.count() + 1)\n",
    "        self.owner_stat.rename(columns={'label': 'owner_mean_label'}, inplace=True)\n",
    "\n",
    "        owner_sum_stat = grp.sum()\n",
    "        owner_cnt_stat = grp.count()\n",
    "        owner_sum_stat.rename(columns={'label': 'owner_sum_label'}, inplace=True)\n",
    "        owner_cnt_stat.rename(columns={'label': 'owner_cnt_label'}, inplace=True)\n",
    "\n",
    "        data = data.join(owner_sum_stat, how='left', on='instanceId_userId')\n",
    "        data = data.join(owner_cnt_stat, how='left', on='instanceId_userId')\n",
    "        data['owner_mean_label'] = (data['owner_sum_label'] - data['label']) / data['owner_cnt_label']\n",
    "        data.drop(['owner_sum_label', 'owner_cnt_label'], 1, inplace=True)\n",
    "        '''\n",
    "        y = data['label']\n",
    "        lgb_train = lgb.Dataset(self.get_X(data), y)\n",
    "        categorical_feature=['assigned_clusters']\n",
    "        \n",
    "        #if self.verbose >= 2:\n",
    "        print('Starting train: %s' % datetime.datetime.now())\n",
    "        params = self.params.copy()\n",
    "        num_boost_round = params['num_boost_round']\n",
    "        del params['num_boost_round']\n",
    "        #params['objective'] = 'binary'\n",
    "        params['metric'] = 'auc'\n",
    "        self.model = lgb.train(\n",
    "            params,\n",
    "            lgb_train,\n",
    "            num_boost_round=num_boost_round\n",
    "        )\n",
    "    def predict(self, data):\n",
    "        #data = data.join(self.owner_stat, how='left', on='metadata_ownerId')\n",
    "        #data = data.join(self.owner_stat, how='left', on='instanceId_userId')\n",
    "        proba = self.model.predict(self.get_X(data))\n",
    "        return proba\n",
    "\n",
    "class KerasModel(MyModel):\n",
    "    def get_X(self, data):\n",
    "        X = super().get_X(data)\n",
    "        X.drop([c for c in X.columns if c.startswith('embedding') and not c.startswith(self.params['emb'])], 1, inplace=True)\n",
    "        X.drop(['end', 'is_ru'], 1, inplace=True)\n",
    "        return X\n",
    "    def fit(self, data):\n",
    "        params = self.params\n",
    "        self.scaler = MyScaler()\n",
    "        X = self.get_X(data)\n",
    "        self.scaler.fit_transform(X, inplace=True)\n",
    "        y = data['label'].values\n",
    "        \n",
    "        model = keras.models.Sequential()\n",
    "        self.model = model\n",
    "\n",
    "        model.add(keras.layers.Dense(params['n1'], activation = \"relu\", input_shape=(X.shape[1], )))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.LeakyReLU())\n",
    "\n",
    "        model.add(keras.layers.Dropout(params['dropout'], noise_shape=None, seed=1))\n",
    "        model.add(keras.layers.Dense(params['n2'], activation = \"relu\"))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        \n",
    "        if 'n3' in params:\n",
    "            model.add(keras.layers.Dropout(params['dropout'], noise_shape=None, seed=1))\n",
    "            model.add(keras.layers.Dense(params['n3'], activation = \"relu\"))\n",
    "            model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "        model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "        model.summary()\n",
    "        model.compile(\n",
    "            optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "            loss = \"binary_crossentropy\",\n",
    "            metrics = [\"accuracy\"]\n",
    "        )\n",
    "        results = model.fit(\n",
    "            X, y,\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params.get('batch_size', 1024),\n",
    "            verbose=params['verbose']\n",
    "        )\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = self.get_X(X)\n",
    "        self.scaler.transform(X, inplace=True)\n",
    "        return self.model.predict(X)[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat(x):\n",
    "    n = x.shape[0]\n",
    "    return np.add.reduce(x.embedding.values) / n\n",
    "\n",
    "class MyScaler():\n",
    "    def fit_transform(self, X, inplace=False):\n",
    "        assert inplace\n",
    "\n",
    "        self.columns = []\n",
    "        for c in X.columns:\n",
    "            if c != 'label':\n",
    "                self.columns.append(c)\n",
    "        \n",
    "        self.means = []\n",
    "        self.sds = []\n",
    "        self.mins = []\n",
    "        self.maxs = []\n",
    "        for c in self.columns:\n",
    "            self.means.append(np.mean(X[c]))\n",
    "            self.sds.append(np.std(X[c]))\n",
    "            self.mins.append(np.min(X[c]))\n",
    "            self.maxs.append(np.max(X[c]))\n",
    "        return self.transform(X, inplace=inplace)\n",
    "    \n",
    "    def transform(self, X, inplace=False):\n",
    "        assert inplace\n",
    "        for c, mean, sd, mn, mx in zip(self.columns, self.means, self.sds, self.mins, self.maxs):\n",
    "            X[c] = ((X[c] - mean) / sd).astype(np.float32)\n",
    "            #X[c] = ((X[c].astype(np.float64) - float(mn)) / (float(mx) - float(mn))).astype(np.float32)\n",
    "        \n",
    "def create_features(data):\n",
    "    ones = np.repeat(1, data.shape[0])\n",
    "    res = pd.DataFrame({\n",
    "        'instanceId_userId': data['instanceId_userId'],\n",
    "        'objectId': data['objectId'],\n",
    "        'object_type': data['instanceId_objectType'],\n",
    "        'client_type': data['audit_clientType'],\n",
    "#        'object_type_0': data['instanceId_objectType'] == 0,\n",
    "#        'object_type_1': data['instanceId_objectType'] == 1,\n",
    "#        'object_type_2': data['instanceId_objectType'] == 2,\n",
    "#        'client_type_0': data['audit_clientType'] == 0,\n",
    "#        'client_type_1': data['audit_clientType'] == 1,\n",
    "#        'client_type_2': data['audit_clientType'] == 2,\n",
    "        \n",
    "        #'is_longread': data['len'] > 400,\n",
    "        #'len': data['len'],\n",
    "        #'p_len': data['p_len'],\n",
    "        'len_log': np.log(data['len'] + 1).astype(np.float32),\n",
    "        'p_len_log': np.log(data['p_len'] + 1).astype(np.float32),\n",
    "        #'plen_per_len': data['p_len'] / data['len'],\n",
    "        'q_count': np.log(data['q_count'] + 1).astype(np.float32),\n",
    "        'links_count': np.log(data['links_count'] + 1).astype(np.float32),\n",
    "        'emojis_rate': (data['emojis_count'] / data['len']).astype(np.float32),\n",
    "        'upper_rate': (data['upper_count'] / data['len']).astype(np.float32),\n",
    "        #'upper_count': data['upper_count'],\n",
    "        'ok_videos_count': data['ok_videos_count'].clip(upper=1).astype(np.int8),\n",
    "        'ok_groups_count': data['ok_groups_count'].clip(upper=1).astype(np.int8),\n",
    "        'youtube_count': data['youtube_count'].clip(upper=1).astype(np.int8),\n",
    "        #'is_video': (data['youtube_count'] + data['ok_videos_count']).clip(upper=1),\n",
    "        'is_adv': data['is_adv'].astype(np.int8),\n",
    "        'is_recipe': data['is_recipe'].astype(np.int8),\n",
    "  #      'brackets_balance': data['brackets_balance'],\n",
    "        'brackets_balance_log': np.log(data['brackets_balance'].abs() + 1).astype(np.float32),\n",
    "        'quotes_count': np.log(data['quotes_count'] + 1).astype(np.float32),\n",
    "        'mdots_count': np.log(data['mdots_count'] + 1).astype(np.float32),\n",
    "        'e_count': np.log(data['e_count'] + 1).astype(np.float32),\n",
    "        #'assigned_clusters': data['assigned_clusters'],\n",
    "        'owner_count': data['owner_count'],\n",
    "        'old': data['audit_timestamp'] - data['metadata_createdAt'],\n",
    "        #'wtf': data['audit_timestamp'] <= data['metadata_createdAt'],\n",
    "        #'mean_target': data['mean_target'],\n",
    "        'has_phone': data['has_phone'].astype(np.int8),                                     #sm+\n",
    "        'hashes_count': np.log(data['hashes_count'] + 1).astype(np.float32),#---\n",
    "        'is_ru': data['lang'] == 'ru',#---\n",
    "        ###'is_day': data['is_day'],#---\n",
    "        'has_newline': data['lines_count'].clip(upper=1).astype(np.int8),                   #sm+\n",
    "        #'object_count': data['object_count'],\n",
    "        'user_count': data['user_count'],\n",
    "        'end': data['e_end'] | data['q_end'] | data['d_end'],#---\n",
    "        ####'md_count': data['md_count'].clip(upper=1),#---\n",
    "        #'positivity': data['positivity'].fillna(0.5).astype(np.float32),\n",
    "        'metadata_ownerId': data['metadata_ownerId'],\n",
    "        #'unliked': data['unliked'],\n",
    "        #'audit_timestamp_day': data['audit_timestamp'] % (3600*24),\n",
    "        #'edits_count': data['edits_count'].clip(upper=2).astype(np.int8),\n",
    "        'edits_count': np.log(data['edits_count'] + 1).astype(np.float32),\n",
    "    })\n",
    "    #qq = data[['instanceId_userId', 'embedding']].join(\n",
    "    #        data.groupby('instanceId_userId').apply(feat).reset_index().set_index('instanceId_userId'), \n",
    "    #        on='instanceId_userId')\n",
    "    #print('Cosing:')\n",
    "    #res['emb_dist'] = (qq.iloc[:,1] - qq.iloc[:,2]).apply(np.linalg.norm)\n",
    "    #res['emb_cosine_dist'] = qq.iloc[:,1:3].apply(lambda x: scipy.spatial.distance.cosine(*x), axis=1)\n",
    "    #print('Embs:')\n",
    "    \n",
    "    #for e in ('embedding_lgb', 'embedding_keras', 'embedding'):\n",
    "    for e in ('embedding_keras',):\n",
    "    #for e in ('embedding',):\n",
    "        emb = np.stack(data[e])\n",
    "        for j in range(emb.shape[1]):\n",
    "            res['%s_%d' % (e, j)] = emb[:,j].astype(np.float32)\n",
    "\n",
    "    if 'liked' in data.columns:\n",
    "        res['label'] = data['liked']\n",
    "    for c in ('clicked', 'viewed', 'disliked', 'reshared', 'ignored', 'commented', 'complaint', 'unliked'):\n",
    "        if c in data.columns:\n",
    "            res[c] = data[c]\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94.7 ms, sys: 95.7 ms, total: 190 ms\n",
      "Wall time: 352 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ttt = create_features(train_data.head(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 46.5 s, total: 2min 4s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = create_features(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[['objectId', 'hashes_count']].groupby('hashes_count').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d0877f670adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medits_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(train.edits_count, 100, color='red', alpha=0.5, stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(np.log(train.edits_count + 1), 100, color='red', alpha=0.5, stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = train[train.instanceId_userId % 4 == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = create_features(train_data[train_data.instanceId_userId % 4 == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-15 13:36:20.121715\n",
      "Fit: 2019-03-15 13:36:30.404223\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      " - 55s - loss: 0.3973 - acc: 0.8486\n",
      "Epoch 2/10\n",
      " - 55s - loss: 0.3890 - acc: 0.8508\n",
      "Epoch 3/10\n",
      " - 55s - loss: 0.3874 - acc: 0.8508\n",
      "Epoch 4/10\n",
      " - 55s - loss: 0.3864 - acc: 0.8508\n",
      "Epoch 5/10\n",
      " - 56s - loss: 0.3857 - acc: 0.8508\n",
      "Epoch 6/10\n",
      " - 56s - loss: 0.3850 - acc: 0.8509\n",
      "Epoch 7/10\n",
      " - 56s - loss: 0.3844 - acc: 0.8509\n",
      "Epoch 8/10\n",
      " - 54s - loss: 0.3839 - acc: 0.8509\n",
      "Epoch 9/10\n",
      " - 53s - loss: 0.3835 - acc: 0.8509\n",
      "Epoch 10/10\n",
      " - 55s - loss: 0.3831 - acc: 0.8509\n",
      "Starting train: 2019-03-15 13:46:16.927366\n",
      "Predict: 2019-03-15 13:52:49.123944\n",
      "Auc: 2019-03-15 13:53:23.959719\n",
      " 0 - 1 : 0.6596, mean=0.6596\n",
      "Prepare data: 2019-03-15 13:53:24.208585\n",
      "Fit: 2019-03-15 13:53:35.279593\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 56s - loss: 0.4000 - acc: 0.8475\n",
      "Epoch 2/10\n",
      " - 55s - loss: 0.3919 - acc: 0.8497\n",
      "Epoch 3/10\n",
      " - 56s - loss: 0.3903 - acc: 0.8497\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-156c83538e55>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(model, data, n_folds, n_iters, seed, verbose, split_by, gv)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fit: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predict: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-6ee629d48d24>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-f97f159fd96b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verbose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         )\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "cross_validation(MeanModel([KerasModel({\n",
    "    'epochs': 10,\n",
    "    'verbose': 2,\n",
    "    'n1': 170,\n",
    "    'n2': 170,\n",
    "    'dropout': 0.1,\n",
    "    'emb': 'embedding_keras',\n",
    "}), LgbModel({\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_data_in_leaf': 25,\n",
    "    'lambda_l2': 0.0,\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.35,\n",
    "    'feature_fraction': 1,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'num_boost_round': 1000,\n",
    "    'verbose': 0\n",
    "})], [0.5, 0.5]), sub, n_iters=1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-15 01:17:09.277304\n",
      "Fit: 2019-03-15 01:17:13.850541\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 63s - loss: 0.3974 - acc: 0.8486\n",
      "Epoch 2/10\n",
      " - 60s - loss: 0.3890 - acc: 0.8508\n",
      "Epoch 3/10\n",
      " - 60s - loss: 0.3874 - acc: 0.8508\n",
      "Epoch 4/10\n",
      " - 61s - loss: 0.3864 - acc: 0.8508\n",
      "Epoch 5/10\n",
      " - 61s - loss: 0.3856 - acc: 0.8509\n",
      "Epoch 6/10\n",
      " - 61s - loss: 0.3849 - acc: 0.8509\n",
      "Epoch 7/10\n",
      " - 62s - loss: 0.3843 - acc: 0.8509\n",
      "Epoch 8/10\n",
      " - 59s - loss: 0.3836 - acc: 0.8509\n",
      "Epoch 9/10\n",
      " - 62s - loss: 0.3832 - acc: 0.8509\n",
      "Epoch 10/10\n",
      " - 62s - loss: 0.3828 - acc: 0.8509\n",
      "Starting train: 2019-03-15 01:27:53.014931\n",
      "Predict: 2019-03-15 01:34:34.032030\n",
      "Auc: 2019-03-15 01:35:23.636532\n",
      " 0 - 1 : 0.6591, mean=0.6591\n",
      "Prepare data: 2019-03-15 01:35:23.918771\n",
      "Fit: 2019-03-15 01:35:35.280016\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 63s - loss: 0.4004 - acc: 0.8474\n",
      "Epoch 2/10\n",
      " - 62s - loss: 0.3921 - acc: 0.8497\n",
      "Epoch 3/10\n",
      " - 61s - loss: 0.3904 - acc: 0.8497\n",
      "Epoch 4/10\n",
      " - 60s - loss: 0.3893 - acc: 0.8497\n",
      "Epoch 5/10\n",
      " - 60s - loss: 0.3884 - acc: 0.8497\n",
      "Epoch 6/10\n",
      " - 61s - loss: 0.3876 - acc: 0.8497\n",
      "Epoch 7/10\n",
      " - 61s - loss: 0.3870 - acc: 0.8497\n",
      "Epoch 8/10\n",
      " - 61s - loss: 0.3864 - acc: 0.8497\n",
      "Epoch 9/10\n",
      " - 61s - loss: 0.3860 - acc: 0.8498\n",
      "Epoch 10/10\n",
      " - 60s - loss: 0.3856 - acc: 0.8498\n",
      "Starting train: 2019-03-15 01:46:07.988114\n",
      "Predict: 2019-03-15 01:52:04.694730\n",
      "Auc: 2019-03-15 01:52:52.174524\n",
      " 0 - 2 : 0.6584, mean=0.6587\n",
      "Prepare data: 2019-03-15 01:52:52.399924\n",
      "Fit: 2019-03-15 01:53:02.473143\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 62s - loss: 0.4058 - acc: 0.8453\n",
      "Epoch 2/10\n",
      " - 60s - loss: 0.3972 - acc: 0.8476\n",
      "Epoch 3/10\n",
      " - 60s - loss: 0.3956 - acc: 0.8476\n",
      "Epoch 4/10\n",
      " - 59s - loss: 0.3945 - acc: 0.8476\n",
      "Epoch 5/10\n",
      " - 61s - loss: 0.3936 - acc: 0.8476\n",
      "Epoch 6/10\n",
      " - 59s - loss: 0.3929 - acc: 0.8476\n",
      "Epoch 7/10\n",
      " - 60s - loss: 0.3922 - acc: 0.8477\n",
      "Epoch 8/10\n",
      " - 61s - loss: 0.3917 - acc: 0.8477\n",
      "Epoch 9/10\n",
      " - 61s - loss: 0.3912 - acc: 0.8477\n",
      "Epoch 10/10\n",
      " - 60s - loss: 0.3908 - acc: 0.8477\n",
      "Starting train: 2019-03-15 02:03:26.972919\n",
      "Predict: 2019-03-15 02:09:30.777613\n",
      "Auc: 2019-03-15 02:10:21.307870\n",
      " 0 - 3 : 0.6590, mean=0.6588\n",
      "Prepare data: 2019-03-15 02:10:21.553742\n",
      "Fit: 2019-03-15 02:10:32.189000\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_56 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 63s - loss: 0.4044 - acc: 0.8458\n",
      "Epoch 2/10\n",
      " - 61s - loss: 0.3960 - acc: 0.8480\n",
      "Epoch 3/10\n",
      " - 62s - loss: 0.3943 - acc: 0.8480\n",
      "Epoch 4/10\n",
      " - 60s - loss: 0.3933 - acc: 0.8480\n",
      "Epoch 5/10\n",
      " - 62s - loss: 0.3925 - acc: 0.8480\n",
      "Epoch 6/10\n",
      " - 61s - loss: 0.3919 - acc: 0.8480\n",
      "Epoch 7/10\n",
      " - 61s - loss: 0.3912 - acc: 0.8480\n",
      "Epoch 8/10\n",
      " - 61s - loss: 0.3907 - acc: 0.8480\n",
      "Epoch 9/10\n",
      " - 62s - loss: 0.3902 - acc: 0.8481\n",
      "Epoch 10/10\n",
      " - 60s - loss: 0.3898 - acc: 0.8480\n",
      "Starting train: 2019-03-15 02:21:07.968834\n",
      "Predict: 2019-03-15 02:27:11.839476\n",
      "Auc: 2019-03-15 02:28:02.346614\n",
      " 0 - 4 : 0.6570, mean=0.6584\n",
      "Prepare data: 2019-03-15 02:28:02.586576\n",
      "Fit: 2019-03-15 02:28:12.919754\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_59 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 63s - loss: 0.4050 - acc: 0.8456\n",
      "Epoch 2/10\n",
      " - 61s - loss: 0.3965 - acc: 0.8478\n",
      "Epoch 3/10\n",
      " - 61s - loss: 0.3948 - acc: 0.8479\n",
      "Epoch 4/10\n",
      " - 61s - loss: 0.3938 - acc: 0.8479\n",
      "Epoch 5/10\n",
      " - 61s - loss: 0.3930 - acc: 0.8479\n",
      "Epoch 6/10\n",
      " - 62s - loss: 0.3922 - acc: 0.8479\n",
      "Epoch 7/10\n",
      " - 60s - loss: 0.3915 - acc: 0.8479\n",
      "Epoch 8/10\n",
      " - 60s - loss: 0.3910 - acc: 0.8479\n",
      "Epoch 9/10\n",
      " - 61s - loss: 0.3904 - acc: 0.8479\n",
      "Epoch 10/10\n",
      " - 62s - loss: 0.3901 - acc: 0.8480\n",
      "Starting train: 2019-03-15 02:38:44.854865\n",
      "Predict: 2019-03-15 02:44:35.049848\n",
      "Auc: 2019-03-15 02:45:26.789399\n",
      " 0 - 5 : 0.6588, mean=0.6584\n",
      "CPU times: user 4h 35min 34s, sys: 23min 15s, total: 4h 58min 50s\n",
      "Wall time: 1h 28min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "cross_validation(MeanModel([KerasModel({\n",
    "    'epochs': 10,\n",
    "    'verbose': 2,\n",
    "    'n1': 170,\n",
    "    'n2': 170,\n",
    "    'dropout': 0.1,\n",
    "    'emb': 'embedding_keras',\n",
    "}), LgbModel({\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_data_in_leaf': 25,\n",
    "    'lambda_l2': 0.0,\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.35,\n",
    "    'feature_fraction': 1,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'num_boost_round': 1000,\n",
    "    'verbose': 0\n",
    "})], [0.5, 0.5]), sub, n_iters=1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-15 00:53:40.974768\n",
      "Fit: 2019-03-15 00:53:53.177971\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,791\n",
      "Trainable params: 48,111\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 63s - loss: 0.3972 - acc: 0.8486\n",
      "Epoch 2/10\n",
      " - 61s - loss: 0.3888 - acc: 0.8508\n",
      "Epoch 3/10\n",
      " - 62s - loss: 0.3872 - acc: 0.8508\n",
      "Epoch 4/10\n",
      " - 60s - loss: 0.3861 - acc: 0.8508\n",
      "Epoch 5/10\n",
      " - 61s - loss: 0.3853 - acc: 0.8508\n",
      "Epoch 6/10\n",
      " - 62s - loss: 0.3846 - acc: 0.8508\n",
      "Epoch 7/10\n",
      " - 62s - loss: 0.3841 - acc: 0.8509\n",
      "Epoch 8/10\n",
      " - 61s - loss: 0.3834 - acc: 0.8509\n",
      "Epoch 9/10\n",
      " - 62s - loss: 0.3831 - acc: 0.8509\n",
      "Epoch 10/10\n",
      " - 62s - loss: 0.3826 - acc: 0.8509\n",
      "Starting train: 2019-03-15 01:04:47.982003\n",
      "Predict: 2019-03-15 01:14:38.149162\n",
      "Auc: 2019-03-15 01:15:31.983790\n",
      " 0 - 1 : 0.6580, mean=0.6580\n",
      "Prepare data: 2019-03-15 01:15:32.246864\n",
      "Fit: 2019-03-15 01:15:43.926053\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-156c83538e55>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(model, data, n_folds, n_iters, seed, verbose, split_by, gv)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fit: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predict: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-6ee629d48d24>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-90cfdc9d6711>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-90cfdc9d6711>\u001b[0m in \u001b[0;36mget_X\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'embedding'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3938\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3939\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3940\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3942\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3778\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3780\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3813\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3815\u001b[0m         \u001b[0;31m# Case for non-unique axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mPY2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3807\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3808\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3809\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reindex_axis'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4342\u001b[0m                for axis, ax in axes.items() if ax is not None):\n\u001b[1;32m   4343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4344\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   5802\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5803\u001b[0m         \"\"\"\n\u001b[0;32m-> 5804\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5805\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         return self.apply('copy', axes=new_axes, deep=deep,\n\u001b[0;32m--> 734\u001b[0;31m                           do_integrity_check=False)\n\u001b[0m\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "cross_validation(MeanModel([KerasModel({\n",
    "    'epochs': 10,\n",
    "    'verbose': 2,\n",
    "    'n1': 170,\n",
    "    'n2': 170,\n",
    "    'dropout': 0.1,\n",
    "    'emb': 'embedding_keras',\n",
    "}), LgbModel({\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_data_in_leaf': 25,\n",
    "    'lambda_l2': 0.0,\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.35,\n",
    "    'feature_fraction': 1,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'num_boost_round': 1000,\n",
    "    'verbose': 0\n",
    "})], [0.5, 0.5]), sub, n_iters=1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-14 17:25:34.794455\n",
      "Fit: 2019-03-14 17:26:27.317152\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,791\n",
      "Trainable params: 48,111\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 73s - loss: 0.3972 - acc: 0.8486\n",
      "Epoch 2/10\n",
      " - 61s - loss: 0.3888 - acc: 0.8508\n",
      "Epoch 3/10\n",
      " - 57s - loss: 0.3873 - acc: 0.8508\n",
      "Epoch 4/10\n",
      " - 58s - loss: 0.3862 - acc: 0.8508\n",
      "Epoch 5/10\n",
      " - 57s - loss: 0.3854 - acc: 0.8508\n",
      "Epoch 6/10\n",
      " - 56s - loss: 0.3847 - acc: 0.8508\n",
      "Epoch 7/10\n",
      " - 56s - loss: 0.3841 - acc: 0.8509\n",
      "Epoch 8/10\n",
      " - 58s - loss: 0.3835 - acc: 0.8509\n",
      "Epoch 9/10\n",
      " - 57s - loss: 0.3831 - acc: 0.8509\n",
      "Epoch 10/10\n",
      " - 57s - loss: 0.3826 - acc: 0.8510\n",
      "Predict: 2019-03-14 17:37:09.892759\n",
      "Auc: 2019-03-14 17:37:32.097842\n",
      " 0 - 1 : 0.6521, mean=0.6521\n",
      "Prepare data: 2019-03-14 17:37:32.340832\n",
      "Fit: 2019-03-14 17:38:01.314460\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,791\n",
      "Trainable params: 48,111\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 57s - loss: 0.4002 - acc: 0.8475\n",
      "Epoch 2/10\n",
      " - 56s - loss: 0.3919 - acc: 0.8497\n",
      "Epoch 3/10\n",
      " - 57s - loss: 0.3904 - acc: 0.8497\n",
      "Epoch 4/10\n",
      " - 56s - loss: 0.3893 - acc: 0.8497\n",
      "Epoch 5/10\n",
      " - 56s - loss: 0.3884 - acc: 0.8497\n",
      "Epoch 6/10\n",
      " - 57s - loss: 0.3878 - acc: 0.8497\n",
      "Epoch 7/10\n",
      " - 56s - loss: 0.3872 - acc: 0.8497\n",
      "Epoch 8/10\n",
      " - 56s - loss: 0.3866 - acc: 0.8497\n",
      "Epoch 9/10\n",
      " - 57s - loss: 0.3861 - acc: 0.8497\n",
      "Epoch 10/10\n",
      " - 58s - loss: 0.3857 - acc: 0.8497\n",
      "Predict: 2019-03-14 17:48:07.697628\n",
      "Auc: 2019-03-14 17:48:31.287179\n",
      " 0 - 2 : 0.6513, mean=0.6517\n",
      "Prepare data: 2019-03-14 17:48:31.550331\n",
      "Fit: 2019-03-14 17:48:58.343204\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,791\n",
      "Trainable params: 48,111\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 56s - loss: 0.4056 - acc: 0.8453\n",
      "Epoch 2/10\n",
      " - 55s - loss: 0.3971 - acc: 0.8476\n",
      "Epoch 3/10\n",
      " - 56s - loss: 0.3955 - acc: 0.8476\n",
      "Epoch 4/10\n",
      " - 55s - loss: 0.3944 - acc: 0.8476\n",
      "Epoch 5/10\n",
      " - 54s - loss: 0.3934 - acc: 0.8476\n",
      "Epoch 6/10\n",
      " - 56s - loss: 0.3926 - acc: 0.8476\n",
      "Epoch 7/10\n",
      " - 55s - loss: 0.3920 - acc: 0.8477\n",
      "Epoch 8/10\n",
      " - 56s - loss: 0.3915 - acc: 0.8477\n",
      "Epoch 9/10\n",
      " - 56s - loss: 0.3910 - acc: 0.8477\n",
      "Epoch 10/10\n",
      " - 56s - loss: 0.3906 - acc: 0.8477\n",
      "Predict: 2019-03-14 17:58:58.407042\n",
      "Auc: 2019-03-14 17:59:23.341948\n",
      " 0 - 3 : 0.6535, mean=0.6523\n",
      "Prepare data: 2019-03-14 17:59:23.615299\n",
      "Fit: 2019-03-14 17:59:48.186683\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,791\n",
      "Trainable params: 48,111\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 57s - loss: 0.4042 - acc: 0.8458\n",
      "Epoch 2/10\n",
      " - 70s - loss: 0.3959 - acc: 0.8480\n",
      "Epoch 3/10\n",
      " - 58s - loss: 0.3942 - acc: 0.8480\n",
      "Epoch 4/10\n",
      " - 58s - loss: 0.3931 - acc: 0.8480\n",
      "Epoch 5/10\n",
      " - 57s - loss: 0.3924 - acc: 0.8480\n",
      "Epoch 6/10\n",
      " - 60s - loss: 0.3918 - acc: 0.8480\n",
      "Epoch 7/10\n",
      " - 58s - loss: 0.3911 - acc: 0.8480\n",
      "Epoch 8/10\n",
      " - 60s - loss: 0.3906 - acc: 0.8480\n",
      "Epoch 9/10\n",
      " - 57s - loss: 0.3901 - acc: 0.8481\n",
      "Epoch 10/10\n",
      " - 61s - loss: 0.3896 - acc: 0.8480\n",
      "Predict: 2019-03-14 18:10:33.925181\n",
      "Auc: 2019-03-14 18:11:00.267407\n",
      " 0 - 4 : 0.6514, mean=0.6521\n",
      "Prepare data: 2019-03-14 18:11:00.543833\n",
      "Fit: 2019-03-14 18:11:30.035667\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,791\n",
      "Trainable params: 48,111\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 59s - loss: 0.4048 - acc: 0.8457\n",
      "Epoch 2/10\n",
      " - 57s - loss: 0.3963 - acc: 0.8479\n",
      "Epoch 3/10\n",
      " - 58s - loss: 0.3947 - acc: 0.8479\n",
      "Epoch 4/10\n",
      " - 56s - loss: 0.3937 - acc: 0.8479\n",
      "Epoch 5/10\n",
      " - 62s - loss: 0.3929 - acc: 0.8479\n",
      "Epoch 6/10\n",
      " - 65s - loss: 0.3922 - acc: 0.8479\n",
      "Epoch 7/10\n",
      " - 65s - loss: 0.3917 - acc: 0.8479\n",
      "Epoch 8/10\n",
      " - 63s - loss: 0.3911 - acc: 0.8479\n",
      "Epoch 9/10\n",
      " - 64s - loss: 0.3905 - acc: 0.8480\n",
      "Epoch 10/10\n",
      " - 63s - loss: 0.3901 - acc: 0.8480\n",
      "Predict: 2019-03-14 18:22:48.522196\n",
      "Auc: 2019-03-14 18:23:14.214882\n",
      " 0 - 5 : 0.6536, mean=0.6524\n",
      "CPU times: user 2h 33min 2s, sys: 23min 27s, total: 2h 56min 29s\n",
      "Wall time: 57min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "cross_validation(KerasModel({\n",
    "    'epochs': 10,\n",
    "    'verbose': 2,\n",
    "    'n1': 170,\n",
    "    'n2': 170,\n",
    "    'dropout': 0.1,\n",
    "    'emb': 'embedding_keras',\n",
    "}), sub, n_iters=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-14 18:23:14.835496\n",
      "Fit: 2019-03-14 18:23:40.606073\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 85)                14535     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 85)                340       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 86        \n",
      "=================================================================\n",
      "Total params: 63,581\n",
      "Trainable params: 62,731\n",
      "Non-trainable params: 850\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 75s - loss: 0.3986 - acc: 0.8481\n",
      "Epoch 2/10\n",
      " - 73s - loss: 0.3894 - acc: 0.8508\n",
      "Epoch 3/10\n",
      " - 76s - loss: 0.3877 - acc: 0.8508\n",
      "Epoch 4/10\n",
      " - 76s - loss: 0.3867 - acc: 0.8508\n",
      "Epoch 5/10\n",
      " - 80s - loss: 0.3859 - acc: 0.8509\n",
      "Epoch 6/10\n",
      " - 73s - loss: 0.3852 - acc: 0.8509\n",
      "Epoch 7/10\n",
      " - 74s - loss: 0.3845 - acc: 0.8509\n",
      "Epoch 8/10\n",
      " - 74s - loss: 0.3840 - acc: 0.8509\n",
      "Epoch 9/10\n",
      " - 73s - loss: 0.3835 - acc: 0.8509\n",
      "Epoch 10/10\n",
      " - 73s - loss: 0.3831 - acc: 0.8510\n",
      "Predict: 2019-03-14 18:37:03.683368\n",
      "Auc: 2019-03-14 18:37:30.340892\n",
      " 0 - 1 : 0.6522, mean=0.6522\n",
      "Prepare data: 2019-03-14 18:37:30.579603\n",
      "Fit: 2019-03-14 18:37:58.010403\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 85)                14535     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 85)                340       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 86        \n",
      "=================================================================\n",
      "Total params: 63,581\n",
      "Trainable params: 62,731\n",
      "Non-trainable params: 850\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 73s - loss: 0.4014 - acc: 0.8470\n",
      "Epoch 2/10\n",
      " - 72s - loss: 0.3921 - acc: 0.8497\n",
      "Epoch 3/10\n",
      " - 72s - loss: 0.3906 - acc: 0.8497\n",
      "Epoch 4/10\n",
      " - 73s - loss: 0.3896 - acc: 0.8497\n",
      "Epoch 5/10\n",
      " - 93s - loss: 0.3888 - acc: 0.8497\n",
      "Epoch 6/10\n",
      " - 92s - loss: 0.3882 - acc: 0.8497\n",
      "Epoch 7/10\n",
      " - 74s - loss: 0.3876 - acc: 0.8497\n",
      "Epoch 8/10\n",
      " - 76s - loss: 0.3870 - acc: 0.8497\n",
      "Epoch 9/10\n",
      " - 76s - loss: 0.3866 - acc: 0.8497\n",
      "Epoch 10/10\n",
      " - 76s - loss: 0.3863 - acc: 0.8498\n",
      "Predict: 2019-03-14 18:51:46.865194\n",
      "Auc: 2019-03-14 18:52:24.002051\n",
      " 0 - 2 : 0.6512, mean=0.6517\n",
      "Prepare data: 2019-03-14 18:52:24.270694\n",
      "Fit: 2019-03-14 18:52:54.496816\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 85)                14535     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 85)                340       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 86        \n",
      "=================================================================\n",
      "Total params: 63,581\n",
      "Trainable params: 62,731\n",
      "Non-trainable params: 850\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 74s - loss: 0.4069 - acc: 0.8448\n",
      "Epoch 2/10\n",
      " - 71s - loss: 0.3975 - acc: 0.8476\n",
      "Epoch 3/10\n",
      " - 71s - loss: 0.3958 - acc: 0.8476\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-156c83538e55>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(model, data, n_folds, n_iters, seed, verbose, split_by, gv)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fit: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predict: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-4091385cc4e1>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verbose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "cross_validation(KerasModel({\n",
    "    'epochs': 10,\n",
    "    'verbose': 2,\n",
    "    'n1': 170,\n",
    "    'n2': 170,\n",
    "    'n3': 85,\n",
    "    'dropout': 0.15,\n",
    "    'emb': 'embedding_keras',\n",
    "}), sub, n_iters=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-13 23:46:59.745711\n",
      "Fit: 2019-03-13 23:47:08.745157\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 170)               21590     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 85)                14535     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 85)                340       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 86        \n",
      "=================================================================\n",
      "Total params: 66,981\n",
      "Trainable params: 66,131\n",
      "Non-trainable params: 850\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 90s - loss: 0.3992 - acc: 0.8485\n",
      "Epoch 2/10\n",
      " - 84s - loss: 0.3909 - acc: 0.8508\n",
      "Epoch 3/10\n",
      " - 80s - loss: 0.3892 - acc: 0.8508\n",
      "Epoch 4/10\n",
      " - 82s - loss: 0.3882 - acc: 0.8508\n",
      "Epoch 5/10\n",
      " - 83s - loss: 0.3874 - acc: 0.8508\n",
      "Epoch 6/10\n",
      " - 76s - loss: 0.3867 - acc: 0.8508\n",
      "Epoch 7/10\n",
      " - 79s - loss: 0.3861 - acc: 0.8508\n",
      "Epoch 8/10\n",
      " - 83s - loss: 0.3857 - acc: 0.8509\n",
      "Epoch 9/10\n",
      " - 82s - loss: 0.3853 - acc: 0.8509\n",
      "Epoch 10/10\n",
      " - 82s - loss: 0.3849 - acc: 0.8509\n",
      "Predict: 2019-03-14 00:01:25.044557\n",
      "Auc: 2019-03-14 00:01:56.381767\n",
      " 0 - 1 : 0.6494, mean=0.6494\n",
      "Prepare data: 2019-03-14 00:01:56.640529\n",
      "Fit: 2019-03-14 00:02:08.819310\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 170)               21590     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 85)                14535     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 85)                340       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 86        \n",
      "=================================================================\n",
      "Total params: 66,981\n",
      "Trainable params: 66,131\n",
      "Non-trainable params: 850\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-156c83538e55>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(model, data, n_folds, n_iters, seed, verbose, split_by, gv)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fit: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predict: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-f8d1febaef70>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verbose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "cross_validation(KerasModel({\n",
    "    'epochs': 10,\n",
    "    'verbose': 2,\n",
    "    'n1': 170,\n",
    "    'n2': 170,\n",
    "    'n3': 85,\n",
    "    'dropout': 0.15,\n",
    "    'emb': 'embedding',\n",
    "}), sub, n_iters=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-14 01:59:21.192266\n",
      "Fit: 2019-03-14 01:59:53.588089\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 170)               40290     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 85)                14535     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 85)                340       \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 86        \n",
      "=================================================================\n",
      "Total params: 85,681\n",
      "Trainable params: 84,831\n",
      "Non-trainable params: 850\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 126s - loss: 0.3984 - acc: 0.8484\n",
      "Epoch 2/10\n",
      " - 124s - loss: 0.3895 - acc: 0.8508\n",
      "Epoch 3/10\n",
      " - 127s - loss: 0.3877 - acc: 0.8508\n",
      "Epoch 4/10\n",
      " - 126s - loss: 0.3866 - acc: 0.8508\n",
      "Epoch 5/10\n",
      " - 128s - loss: 0.3857 - acc: 0.8508\n",
      "Epoch 6/10\n",
      " - 122s - loss: 0.3850 - acc: 0.8508\n",
      "Epoch 7/10\n",
      " - 127s - loss: 0.3844 - acc: 0.8509\n",
      "Epoch 8/10\n",
      " - 127s - loss: 0.3838 - acc: 0.8509\n",
      "Epoch 9/10\n",
      " - 127s - loss: 0.3832 - acc: 0.8509\n",
      "Epoch 10/10\n",
      " - 122s - loss: 0.3827 - acc: 0.8509\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,791\n",
      "Trainable params: 48,111\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 59s - loss: 0.3973 - acc: 0.8487\n",
      "Epoch 2/10\n",
      " - 59s - loss: 0.3888 - acc: 0.8508\n",
      "Epoch 3/10\n",
      " - 59s - loss: 0.3873 - acc: 0.8508\n",
      "Epoch 4/10\n",
      " - 56s - loss: 0.3863 - acc: 0.8508\n",
      "Epoch 5/10\n",
      " - 60s - loss: 0.3854 - acc: 0.8508\n",
      "Epoch 6/10\n",
      " - 60s - loss: 0.3847 - acc: 0.8509\n",
      "Epoch 7/10\n",
      " - 59s - loss: 0.3841 - acc: 0.8509\n",
      "Epoch 8/10\n",
      " - 59s - loss: 0.3836 - acc: 0.8509\n",
      "Epoch 9/10\n",
      " - 62s - loss: 0.3832 - acc: 0.8509\n",
      "Epoch 10/10\n",
      " - 60s - loss: 0.3828 - acc: 0.8509\n",
      "Starting train: 2019-03-14 02:32:36.272667\n",
      "Predict: 2019-03-14 02:40:49.326263\n",
      "Auc: 2019-03-14 02:41:58.634544\n",
      " 0 - 1 : 0.6595, mean=0.6595\n",
      "Prepare data: 2019-03-14 02:41:58.851666\n",
      "Fit: 2019-03-14 02:42:23.937525\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 170)               40290     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 85)                14535     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 85)                340       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 86        \n",
      "=================================================================\n",
      "Total params: 85,681\n",
      "Trainable params: 84,831\n",
      "Non-trainable params: 850\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 129s - loss: 0.4013 - acc: 0.8471\n",
      "Epoch 2/10\n",
      " - 119s - loss: 0.3925 - acc: 0.8497\n",
      "Epoch 3/10\n",
      " - 127s - loss: 0.3906 - acc: 0.8497\n",
      "Epoch 4/10\n",
      " - 126s - loss: 0.3895 - acc: 0.8497\n",
      "Epoch 5/10\n",
      " - 122s - loss: 0.3886 - acc: 0.8497\n",
      "Epoch 6/10\n",
      " - 127s - loss: 0.3879 - acc: 0.8497\n",
      "Epoch 7/10\n",
      " - 125s - loss: 0.3873 - acc: 0.8497\n",
      "Epoch 8/10\n",
      " - 126s - loss: 0.3868 - acc: 0.8497\n",
      "Epoch 9/10\n",
      " - 123s - loss: 0.3862 - acc: 0.8497\n",
      "Epoch 10/10\n",
      " - 126s - loss: 0.3858 - acc: 0.8498\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,791\n",
      "Trainable params: 48,111\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 61s - loss: 0.4005 - acc: 0.8474\n",
      "Epoch 2/10\n",
      " - 59s - loss: 0.3921 - acc: 0.8497\n",
      "Epoch 3/10\n",
      " - 60s - loss: 0.3904 - acc: 0.8497\n",
      "Epoch 4/10\n",
      " - 58s - loss: 0.3894 - acc: 0.8497\n",
      "Epoch 5/10\n",
      " - 60s - loss: 0.3885 - acc: 0.8497\n",
      "Epoch 6/10\n",
      " - 59s - loss: 0.3877 - acc: 0.8497\n",
      "Epoch 7/10\n",
      " - 60s - loss: 0.3870 - acc: 0.8497\n",
      "Epoch 8/10\n",
      " - 55s - loss: 0.3864 - acc: 0.8497\n",
      "Epoch 9/10\n",
      " - 60s - loss: 0.3860 - acc: 0.8497\n",
      "Epoch 10/10\n",
      " - 58s - loss: 0.3856 - acc: 0.8497\n",
      "Starting train: 2019-03-14 03:14:32.891456\n",
      "Predict: 2019-03-14 03:22:43.203584\n",
      "Auc: 2019-03-14 03:23:59.388515\n",
      " 0 - 2 : 0.6598, mean=0.6597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data: 2019-03-14 03:23:59.636542\n",
      "Fit: 2019-03-14 03:24:23.414990\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 170)               40290     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 85)                14535     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 85)                340       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 86        \n",
      "=================================================================\n",
      "Total params: 85,681\n",
      "Trainable params: 84,831\n",
      "Non-trainable params: 850\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 126s - loss: 0.4065 - acc: 0.8451\n",
      "Epoch 2/10\n",
      " - 122s - loss: 0.3976 - acc: 0.8476\n",
      "Epoch 3/10\n",
      " - 122s - loss: 0.3958 - acc: 0.8476\n",
      "Epoch 4/10\n",
      " - 124s - loss: 0.3946 - acc: 0.8476\n",
      "Epoch 5/10\n",
      " - 121s - loss: 0.3937 - acc: 0.8476\n",
      "Epoch 6/10\n",
      " - 124s - loss: 0.3930 - acc: 0.8476\n",
      "Epoch 7/10\n",
      " - 119s - loss: 0.3924 - acc: 0.8476\n",
      "Epoch 8/10\n",
      " - 114s - loss: 0.3918 - acc: 0.8476\n",
      "Epoch 9/10\n",
      " - 121s - loss: 0.3913 - acc: 0.8477\n",
      "Epoch 10/10\n",
      " - 123s - loss: 0.3907 - acc: 0.8477\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,791\n",
      "Trainable params: 48,111\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 59s - loss: 0.4057 - acc: 0.8452\n",
      "Epoch 2/10\n",
      " - 59s - loss: 0.3972 - acc: 0.8476\n",
      "Epoch 3/10\n",
      " - 60s - loss: 0.3955 - acc: 0.8476\n",
      "Epoch 4/10\n",
      " - 60s - loss: 0.3944 - acc: 0.8476\n",
      "Epoch 5/10\n",
      " - 59s - loss: 0.3935 - acc: 0.8476\n",
      "Epoch 6/10\n",
      " - 59s - loss: 0.3928 - acc: 0.8476\n",
      "Epoch 7/10\n",
      " - 57s - loss: 0.3921 - acc: 0.8477\n",
      "Epoch 8/10\n",
      " - 59s - loss: 0.3915 - acc: 0.8477\n",
      "Epoch 9/10\n",
      " - 60s - loss: 0.3911 - acc: 0.8477\n",
      "Epoch 10/10\n",
      " - 60s - loss: 0.3907 - acc: 0.8477\n",
      "Starting train: 2019-03-14 03:55:56.370885\n",
      "Predict: 2019-03-14 04:03:56.342291\n",
      "Auc: 2019-03-14 04:05:19.387050\n",
      " 0 - 3 : 0.6604, mean=0.6599\n",
      "Prepare data: 2019-03-14 04:05:19.667570\n",
      "Fit: 2019-03-14 04:05:44.232476\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 170)               40290     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 85)                14535     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 85)                340       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 86        \n",
      "=================================================================\n",
      "Total params: 85,681\n",
      "Trainable params: 84,831\n",
      "Non-trainable params: 850\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 127s - loss: 0.4052 - acc: 0.8455\n",
      "Epoch 2/10\n",
      " - 123s - loss: 0.3964 - acc: 0.8480\n",
      "Epoch 3/10\n",
      " - 126s - loss: 0.3946 - acc: 0.8480\n",
      "Epoch 4/10\n",
      " - 119s - loss: 0.3935 - acc: 0.8480\n",
      "Epoch 5/10\n",
      " - 125s - loss: 0.3927 - acc: 0.8480\n",
      "Epoch 6/10\n",
      " - 126s - loss: 0.3920 - acc: 0.8480\n",
      "Epoch 7/10\n",
      " - 126s - loss: 0.3914 - acc: 0.8480\n",
      "Epoch 8/10\n",
      " - 126s - loss: 0.3908 - acc: 0.8480\n",
      "Epoch 9/10\n",
      " - 126s - loss: 0.3904 - acc: 0.8480\n",
      "Epoch 10/10\n",
      " - 123s - loss: 0.3900 - acc: 0.8481\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,791\n",
      "Trainable params: 48,111\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 62s - loss: 0.4044 - acc: 0.8456\n",
      "Epoch 2/10\n",
      " - 59s - loss: 0.3959 - acc: 0.8480\n",
      "Epoch 3/10\n",
      " - 60s - loss: 0.3943 - acc: 0.8480\n",
      "Epoch 4/10\n",
      " - 60s - loss: 0.3932 - acc: 0.8480\n",
      "Epoch 5/10\n",
      " - 60s - loss: 0.3925 - acc: 0.8480\n",
      "Epoch 6/10\n",
      " - 59s - loss: 0.3917 - acc: 0.8480\n",
      "Epoch 7/10\n",
      " - 60s - loss: 0.3911 - acc: 0.8480\n",
      "Epoch 8/10\n",
      " - 54s - loss: 0.3905 - acc: 0.8480\n",
      "Epoch 9/10\n",
      " - 55s - loss: 0.3899 - acc: 0.8480\n",
      "Epoch 10/10\n",
      " - 61s - loss: 0.3894 - acc: 0.8481\n",
      "Starting train: 2019-03-14 04:37:59.011648\n",
      "Predict: 2019-03-14 04:45:55.475219\n",
      "Auc: 2019-03-14 04:47:20.328293\n",
      " 0 - 4 : 0.6580, mean=0.6594\n",
      "Prepare data: 2019-03-14 04:47:20.600326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit: 2019-03-14 04:47:44.311251\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 170)               40290     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 85)                14535     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 85)                340       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 86        \n",
      "=================================================================\n",
      "Total params: 85,681\n",
      "Trainable params: 84,831\n",
      "Non-trainable params: 850\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 126s - loss: 0.4054 - acc: 0.8454\n",
      "Epoch 2/10\n",
      " - 122s - loss: 0.3966 - acc: 0.8479\n",
      "Epoch 3/10\n",
      " - 126s - loss: 0.3949 - acc: 0.8479\n",
      "Epoch 4/10\n",
      " - 122s - loss: 0.3938 - acc: 0.8479\n",
      "Epoch 5/10\n",
      " - 124s - loss: 0.3930 - acc: 0.8479\n",
      "Epoch 6/10\n",
      " - 118s - loss: 0.3923 - acc: 0.8479\n",
      "Epoch 7/10\n",
      " - 115s - loss: 0.3917 - acc: 0.8479\n",
      "Epoch 8/10\n",
      " - 122s - loss: 0.3911 - acc: 0.8479\n",
      "Epoch 9/10\n",
      " - 126s - loss: 0.3906 - acc: 0.8479\n",
      "Epoch 10/10\n",
      " - 125s - loss: 0.3901 - acc: 0.8479\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,791\n",
      "Trainable params: 48,111\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 61s - loss: 0.4049 - acc: 0.8456\n",
      "Epoch 2/10\n",
      " - 60s - loss: 0.3962 - acc: 0.8479\n",
      "Epoch 3/10\n",
      " - 61s - loss: 0.3945 - acc: 0.8479\n",
      "Epoch 4/10\n",
      " - 61s - loss: 0.3934 - acc: 0.8479\n",
      "Epoch 5/10\n",
      " - 61s - loss: 0.3925 - acc: 0.8479\n",
      "Epoch 6/10\n",
      " - 60s - loss: 0.3918 - acc: 0.8479\n",
      "Epoch 7/10\n",
      " - 61s - loss: 0.3912 - acc: 0.8479\n",
      "Epoch 8/10\n",
      " - 61s - loss: 0.3907 - acc: 0.8479\n",
      "Epoch 9/10\n",
      " - 61s - loss: 0.3902 - acc: 0.8480\n",
      "Epoch 10/10\n",
      " - 61s - loss: 0.3897 - acc: 0.8480\n",
      "Starting train: 2019-03-14 05:19:49.400681\n",
      "Predict: 2019-03-14 05:27:48.221150\n",
      "Auc: 2019-03-14 05:29:18.164956\n",
      " 0 - 5 : 0.6612, mean=0.6598\n",
      "CPU times: user 9h 43min 27s, sys: 1h 29min 18s, total: 11h 12min 46s\n",
      "Wall time: 3h 29min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "cross_validation(MeanModel([KerasModel({\n",
    "    'epochs': 10,\n",
    "    'verbose': 2,\n",
    "    'n1': 170,\n",
    "    'n2': 170,\n",
    "    'n3': 85,\n",
    "    'dropout': 0.15,\n",
    "    'emb': 'embedding',\n",
    "}), KerasModel({\n",
    "    'epochs': 10,\n",
    "    'verbose': 2,\n",
    "    'n1': 170,\n",
    "    'n2': 170,\n",
    "    'dropout': 0.1,\n",
    "    'emb': 'embedding_keras',\n",
    "}), LgbModel({\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_data_in_leaf': 25,\n",
    "    'lambda_l2': 0.0,\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.35,\n",
    "    'feature_fraction': 1,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'num_boost_round': 1000,\n",
    "    'verbose': 0\n",
    "})], [0.3, 0.5, 0.5]), sub, n_iters=1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 0.0, 0.35, 1, 1000, 30)\n",
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-13 13:30:11.582781\n",
      "Fit: 2019-03-13 13:30:28.158089\n",
      "Starting train: 2019-03-13 13:30:34.775824\n",
      "Predict: 2019-03-13 13:39:14.415133\n",
      "Auc: 2019-03-13 13:39:54.823917\n",
      " 0 - 1 : 0.6394, mean=0.6394\n",
      "Prepare data: 2019-03-13 13:39:55.225376\n",
      "Fit: 2019-03-13 13:40:21.320190\n",
      "Starting train: 2019-03-13 13:40:32.937569\n",
      "Predict: 2019-03-13 13:49:35.452707\n",
      "Auc: 2019-03-13 13:50:08.747280\n",
      " 0 - 2 : 0.6399, mean=0.6396\n",
      "Prepare data: 2019-03-13 13:50:09.102442\n",
      "Fit: 2019-03-13 13:50:27.241335\n",
      "Starting train: 2019-03-13 13:50:34.803271\n",
      "Predict: 2019-03-13 13:59:36.005910\n",
      "Auc: 2019-03-13 14:00:10.849836\n",
      " 0 - 3 : 0.6383, mean=0.6392\n",
      "Prepare data: 2019-03-13 14:00:11.209648\n",
      "Fit: 2019-03-13 14:00:27.990000\n",
      "Starting train: 2019-03-13 14:00:35.559242\n",
      "Predict: 2019-03-13 14:09:26.295078\n",
      "Auc: 2019-03-13 14:09:53.007898\n",
      " 0 - 4 : 0.6360, mean=0.6384\n",
      "Prepare data: 2019-03-13 14:09:53.339077\n",
      "Fit: 2019-03-13 14:10:15.139445\n",
      "Starting train: 2019-03-13 14:10:26.816011\n",
      "Predict: 2019-03-13 14:19:11.166506\n",
      "Auc: 2019-03-13 14:19:43.132884\n",
      " 0 - 5 : 0.6379, mean=0.6383\n",
      "CPU times: user 2h 10min 31s, sys: 9min 57s, total: 2h 20min 29s\n",
      "Wall time: 49min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################################### new\n",
    "for min_data_in_leaf in (25,):\n",
    "    for lambda_l2 in (0.0,):\n",
    "        for learning_rate in (0.35,):\n",
    "            for feature_fraction in (1,):\n",
    "                for num_boost_round in (1000,):\n",
    "                    for num_leaves in (30,):\n",
    "                        print((min_data_in_leaf,lambda_l2,learning_rate,feature_fraction,num_boost_round,num_leaves))\n",
    "                        cross_validation(LgbModel({\n",
    "                            'boosting_type': 'gbdt',\n",
    "                            'min_data_in_leaf': min_data_in_leaf,\n",
    "                            'lambda_l2': lambda_l2,\n",
    "                            'num_leaves': num_leaves,\n",
    "                            'learning_rate': learning_rate,\n",
    "                            'feature_fraction': feature_fraction,\n",
    "                            'bagging_fraction': 1,\n",
    "                            'bagging_freq': 5,\n",
    "                            'num_boost_round': num_boost_round,\n",
    "                            #'max_depth': 4,\n",
    "                            'verbose': 0\n",
    "                        }), sub, n_iters=1, verbose=2, split_by='objectId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 0.0, 0.35, 1, 1000, 30)\n",
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-13 11:04:15.825459\n",
      "Fit: 2019-03-13 11:04:27.095029\n",
      "Starting train: 2019-03-13 11:04:34.196130\n",
      "Predict: 2019-03-13 11:08:46.388544\n",
      "Auc: 2019-03-13 11:09:08.600697\n",
      " 0 - 1 : 0.6410, mean=0.6410\n",
      "Prepare data: 2019-03-13 11:09:09.021813\n",
      "Fit: 2019-03-13 11:09:24.230877\n",
      "Starting train: 2019-03-13 11:09:27.807317\n",
      "Predict: 2019-03-13 11:13:32.271267\n",
      "Auc: 2019-03-13 11:13:50.741636\n",
      " 0 - 2 : 0.6365, mean=0.6388\n",
      "Prepare data: 2019-03-13 11:13:51.044617\n",
      "Fit: 2019-03-13 11:14:05.955971\n",
      "Starting train: 2019-03-13 11:14:13.692660\n",
      "Predict: 2019-03-13 11:18:26.937961\n",
      "Auc: 2019-03-13 11:18:47.643365\n",
      " 0 - 3 : 0.6366, mean=0.6381\n",
      "Prepare data: 2019-03-13 11:18:47.984787\n",
      "Fit: 2019-03-13 11:19:12.793454\n",
      "Starting train: 2019-03-13 11:19:22.310795\n",
      "Predict: 2019-03-13 11:23:50.365574\n",
      "Auc: 2019-03-13 11:24:10.249879\n",
      " 0 - 4 : 0.6357, mean=0.6375\n",
      "Prepare data: 2019-03-13 11:24:10.550065\n",
      "Fit: 2019-03-13 11:24:28.055716\n",
      "Starting train: 2019-03-13 11:24:35.804925\n",
      "Predict: 2019-03-13 11:28:55.406623\n",
      "Auc: 2019-03-13 11:29:14.610977\n",
      " 0 - 5 : 0.6361, mean=0.6372\n",
      "CPU times: user 1h 16min 4s, sys: 3min 11s, total: 1h 19min 16s\n",
      "Wall time: 24min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "####################################  \n",
    "for min_data_in_leaf in (25,):\n",
    "    for lambda_l2 in (0.0,):\n",
    "        for learning_rate in (0.35,):\n",
    "            for feature_fraction in (1,):\n",
    "                for num_boost_round in (1000,):\n",
    "                    for num_leaves in (30,):\n",
    "                        print((min_data_in_leaf,lambda_l2,learning_rate,feature_fraction,num_boost_round,num_leaves))\n",
    "                        cross_validation(LgbModel({\n",
    "                            'boosting_type': 'gbdt',\n",
    "                            'min_data_in_leaf': min_data_in_leaf,\n",
    "                            'lambda_l2': lambda_l2,\n",
    "                            'num_leaves': num_leaves,\n",
    "                            'learning_rate': learning_rate,\n",
    "                            'feature_fraction': feature_fraction,\n",
    "                            'bagging_fraction': 1,\n",
    "                            'bagging_freq': 5,\n",
    "                            'num_boost_round': num_boost_round,\n",
    "                            #'max_depth': 4,\n",
    "                            'verbose': 0\n",
    "                        }), sub, n_iters=1, verbose=2, split_by='objectId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-11 01:03:47.840738\n",
      "Fit: 2019-03-11 01:03:55.981848\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 71s - loss: 0.3998 - acc: 0.8486\n",
      "Epoch 2/10\n",
      " - 58s - loss: 0.3914 - acc: 0.8508\n",
      "Epoch 3/10\n",
      " - 60s - loss: 0.3898 - acc: 0.8508\n",
      "Epoch 4/10\n",
      " - 60s - loss: 0.3888 - acc: 0.8508\n",
      "Epoch 5/10\n",
      " - 60s - loss: 0.3880 - acc: 0.8508\n",
      "Epoch 6/10\n",
      " - 59s - loss: 0.3873 - acc: 0.8508\n",
      "Epoch 7/10\n",
      " - 58s - loss: 0.3868 - acc: 0.8508\n",
      "Epoch 8/10\n",
      " - 60s - loss: 0.3864 - acc: 0.8508\n",
      "Epoch 9/10\n",
      " - 61s - loss: 0.3860 - acc: 0.8508\n",
      "Epoch 10/10\n",
      " - 59s - loss: 0.3857 - acc: 0.8508\n",
      "Starting train: 2019-03-11 01:14:37.158468\n",
      "Predict: 2019-03-11 01:18:28.462299\n",
      "Auc: 2019-03-11 01:19:12.046194\n",
      " 0 - 1 : 0.6550, mean=0.6550\n",
      "Prepare data: 2019-03-11 01:19:12.265218\n",
      "Fit: 2019-03-11 01:19:27.600778\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 67s - loss: 0.4027 - acc: 0.8474\n",
      "Epoch 2/10\n",
      " - 57s - loss: 0.3944 - acc: 0.8497\n",
      "Epoch 3/10\n",
      " - 59s - loss: 0.3928 - acc: 0.8497\n",
      "Epoch 4/10\n",
      " - 59s - loss: 0.3919 - acc: 0.8497\n",
      "Epoch 5/10\n",
      " - 59s - loss: 0.3911 - acc: 0.8497\n",
      "Epoch 6/10\n",
      " - 58s - loss: 0.3905 - acc: 0.8497\n",
      "Epoch 7/10\n",
      " - 58s - loss: 0.3899 - acc: 0.8497\n",
      "Epoch 8/10\n",
      " - 60s - loss: 0.3894 - acc: 0.8497\n",
      "Epoch 9/10\n",
      " - 59s - loss: 0.3890 - acc: 0.8497\n",
      "Epoch 10/10\n",
      " - 59s - loss: 0.3886 - acc: 0.8497\n",
      "Starting train: 2019-03-11 01:29:53.241385\n",
      "Predict: 2019-03-11 01:33:40.791928\n",
      "Auc: 2019-03-11 01:34:27.651800\n",
      " 0 - 2 : 0.6541, mean=0.6546\n",
      "Prepare data: 2019-03-11 01:34:27.888684\n",
      "Fit: 2019-03-11 01:34:41.633260\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 62s - loss: 0.4081 - acc: 0.8453\n",
      "Epoch 2/10\n",
      " - 57s - loss: 0.3998 - acc: 0.8476\n",
      "Epoch 3/10\n",
      " - 59s - loss: 0.3983 - acc: 0.8476\n",
      "Epoch 4/10\n",
      " - 57s - loss: 0.3973 - acc: 0.8476\n",
      "Epoch 5/10\n",
      " - 59s - loss: 0.3965 - acc: 0.8476\n",
      "Epoch 6/10\n",
      " - 58s - loss: 0.3957 - acc: 0.8476\n",
      "Epoch 7/10\n",
      " - 59s - loss: 0.3951 - acc: 0.8476\n",
      "Epoch 8/10\n",
      " - 58s - loss: 0.3946 - acc: 0.8476\n",
      "Epoch 9/10\n",
      " - 58s - loss: 0.3942 - acc: 0.8476\n",
      "Epoch 10/10\n",
      " - 59s - loss: 0.3939 - acc: 0.8476\n",
      "Starting train: 2019-03-11 01:45:01.938676\n",
      "Predict: 2019-03-11 01:48:50.814095\n",
      "Auc: 2019-03-11 01:49:39.372318\n",
      " 0 - 3 : 0.6553, mean=0.6548\n",
      "Prepare data: 2019-03-11 01:49:39.629435\n",
      "Fit: 2019-03-11 01:49:53.718912\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 67s - loss: 0.4069 - acc: 0.8457\n",
      "Epoch 2/10\n",
      " - 59s - loss: 0.3982 - acc: 0.8480\n",
      "Epoch 3/10\n",
      " - 58s - loss: 0.3967 - acc: 0.8480\n",
      "Epoch 4/10\n",
      " - 59s - loss: 0.3957 - acc: 0.8480\n",
      "Epoch 5/10\n",
      " - 59s - loss: 0.3950 - acc: 0.8480\n",
      "Epoch 6/10\n",
      " - 59s - loss: 0.3944 - acc: 0.8480\n",
      "Epoch 7/10\n",
      " - 59s - loss: 0.3939 - acc: 0.8480\n",
      "Epoch 8/10\n",
      " - 59s - loss: 0.3934 - acc: 0.8480\n",
      "Epoch 9/10\n",
      " - 60s - loss: 0.3930 - acc: 0.8480\n",
      "Epoch 10/10\n",
      " - 59s - loss: 0.3927 - acc: 0.8480\n",
      "Starting train: 2019-03-11 02:00:28.020508\n",
      "Predict: 2019-03-11 02:04:19.485171\n",
      "Auc: 2019-03-11 02:05:08.536195\n",
      " 0 - 4 : 0.6551, mean=0.6549\n",
      "Prepare data: 2019-03-11 02:05:08.776609\n",
      "Fit: 2019-03-11 02:05:22.906365\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 66s - loss: 0.4074 - acc: 0.8456\n",
      "Epoch 2/10\n",
      " - 60s - loss: 0.3990 - acc: 0.8478\n",
      "Epoch 3/10\n",
      " - 59s - loss: 0.3973 - acc: 0.8479\n",
      "Epoch 4/10\n",
      " - 59s - loss: 0.3964 - acc: 0.8479\n",
      "Epoch 5/10\n",
      " - 60s - loss: 0.3956 - acc: 0.8479\n",
      "Epoch 6/10\n",
      " - 59s - loss: 0.3949 - acc: 0.8479\n",
      "Epoch 7/10\n",
      " - 58s - loss: 0.3944 - acc: 0.8479\n",
      "Epoch 8/10\n",
      " - 58s - loss: 0.3939 - acc: 0.8479\n",
      "Epoch 9/10\n",
      " - 59s - loss: 0.3935 - acc: 0.8479\n",
      "Epoch 10/10\n",
      " - 60s - loss: 0.3931 - acc: 0.8479\n",
      "Starting train: 2019-03-11 02:15:50.197920\n",
      "Predict: 2019-03-11 02:19:41.508979\n",
      "Auc: 2019-03-11 02:20:31.741966\n",
      " 0 - 5 : 0.6561, mean=0.6551\n",
      "CPU times: user 3h 47min 49s, sys: 23min 49s, total: 4h 11min 39s\n",
      "Wall time: 1h 16min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "cross_validation(MeanModel([KerasModel({\n",
    "    'epochs': 10,\n",
    "    'verbose': 2,\n",
    "}), LgbModel({\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_data_in_leaf': 25,\n",
    "    'lambda_l2': 0.0,\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.35,\n",
    "    'feature_fraction': 1,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'num_boost_round': 1000,\n",
    "    'verbose': 0\n",
    "})], [0.5, 0.5]), sub, n_iters=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-11 05:49:57.609789\n",
      "Fit: 2019-03-11 05:51:13.283459\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 297s - loss: 0.4094 - acc: 0.8439\n",
      "Epoch 2/10\n",
      " - 273s - loss: 0.4050 - acc: 0.8445\n",
      "Epoch 3/10\n",
      " - 278s - loss: 0.4039 - acc: 0.8445\n",
      "Epoch 4/10\n",
      " - 277s - loss: 0.4030 - acc: 0.8445\n",
      "Epoch 5/10\n",
      " - 278s - loss: 0.4025 - acc: 0.8445\n",
      "Epoch 6/10\n",
      " - 281s - loss: 0.4021 - acc: 0.8445\n",
      "Epoch 7/10\n",
      " - 282s - loss: 0.4019 - acc: 0.8445\n",
      "Epoch 8/10\n",
      " - 282s - loss: 0.4016 - acc: 0.8445\n",
      "Epoch 9/10\n",
      " - 277s - loss: 0.4015 - acc: 0.8445\n",
      "Epoch 10/10\n",
      " - 279s - loss: 0.4013 - acc: 0.8445\n",
      "Starting train: 2019-03-11 06:42:18.693839\n",
      "Predict: 2019-03-11 07:03:26.583546\n",
      "Auc: 2019-03-11 07:07:25.938526\n",
      " 0 - 1 : 0.6623, mean=0.6623\n",
      "Prepare data: 2019-03-11 07:07:27.080783\n",
      "Fit: 2019-03-11 07:08:48.111448\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 316s - loss: 0.4070 - acc: 0.8450\n",
      "Epoch 2/10\n",
      " - 279s - loss: 0.4026 - acc: 0.8456\n",
      "Epoch 3/10\n",
      " - 285s - loss: 0.4015 - acc: 0.8456\n",
      "Epoch 4/10\n",
      " - 282s - loss: 0.4006 - acc: 0.8456\n",
      "Epoch 5/10\n",
      " - 275s - loss: 0.4000 - acc: 0.8456\n",
      "Epoch 6/10\n",
      " - 281s - loss: 0.3997 - acc: 0.8456\n",
      "Epoch 7/10\n",
      " - 280s - loss: 0.3994 - acc: 0.8456\n",
      "Epoch 8/10\n",
      " - 273s - loss: 0.3992 - acc: 0.8456\n",
      "Epoch 9/10\n",
      " - 282s - loss: 0.3990 - acc: 0.8456\n",
      "Epoch 10/10\n",
      " - 282s - loss: 0.3989 - acc: 0.8456\n",
      "Starting train: 2019-03-11 08:00:27.611389\n",
      "Predict: 2019-03-11 08:21:33.017738\n",
      "Auc: 2019-03-11 08:25:30.943152\n",
      " 0 - 2 : 0.6627, mean=0.6625\n",
      "Prepare data: 2019-03-11 08:25:32.068016\n",
      "Fit: 2019-03-11 08:26:51.841052\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_66 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 285s - loss: 0.4075 - acc: 0.8447\n",
      "Epoch 2/10\n",
      " - 282s - loss: 0.4031 - acc: 0.8453\n",
      "Epoch 3/10\n",
      " - 283s - loss: 0.4018 - acc: 0.8453\n",
      "Epoch 4/10\n",
      " - 278s - loss: 0.4011 - acc: 0.8453\n",
      "Epoch 5/10\n",
      " - 279s - loss: 0.4006 - acc: 0.8453\n",
      "Epoch 6/10\n",
      " - 283s - loss: 0.4003 - acc: 0.8453\n",
      "Epoch 7/10\n",
      " - 281s - loss: 0.4000 - acc: 0.8453\n",
      "Epoch 8/10\n",
      " - 280s - loss: 0.3998 - acc: 0.8453\n",
      "Epoch 9/10\n",
      " - 276s - loss: 0.3996 - acc: 0.8453\n",
      "Epoch 10/10\n",
      " - 282s - loss: 0.3995 - acc: 0.8453\n",
      "Starting train: 2019-03-11 09:18:14.585233\n",
      "Predict: 2019-03-11 10:38:11.697091\n",
      "Auc: 2019-03-11 10:42:45.270594\n",
      " 0 - 3 : 0.6628, mean=0.6626\n",
      "Prepare data: 2019-03-11 10:42:46.514781\n",
      "Fit: 2019-03-11 10:44:12.328391\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_69 (Dense)             (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "cross_validation(MeanModel([KerasModel({\n",
    "    'epochs': 10,\n",
    "    'verbose': 2,\n",
    "}), LgbModel({\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_data_in_leaf': 25,\n",
    "    'lambda_l2': 0.0,\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.35,\n",
    "    'feature_fraction': 1,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'num_boost_round': 1000,\n",
    "    'verbose': 0\n",
    "})], [0.5, 0.5]), train, n_iters=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-10 12:16:23.137937\n",
      "Fit: 2019-03-10 12:16:36.255492\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 170)               18020     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 47,261\n",
      "Trainable params: 47,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 52s - loss: 0.3944 - acc: 0.8508\n",
      "Epoch 2/10\n",
      " - 51s - loss: 0.3893 - acc: 0.8508\n",
      "Epoch 3/10\n",
      " - 51s - loss: 0.3879 - acc: 0.8508\n",
      "Epoch 4/10\n",
      " - 52s - loss: 0.3871 - acc: 0.8508\n",
      "Epoch 5/10\n",
      " - 52s - loss: 0.3864 - acc: 0.8508\n",
      "Epoch 6/10\n",
      " - 52s - loss: 0.3858 - acc: 0.8509\n",
      "Epoch 7/10\n",
      " - 51s - loss: 0.3853 - acc: 0.8509\n",
      "Epoch 8/10\n",
      " - 51s - loss: 0.3849 - acc: 0.8509\n",
      "Epoch 9/10\n",
      " - 52s - loss: 0.3845 - acc: 0.8509\n",
      "Epoch 10/10\n",
      " - 48s - loss: 0.3842 - acc: 0.8509\n",
      "Starting train: 2019-03-10 12:27:32.710174\n",
      "Predict: 2019-03-10 12:31:18.837712\n",
      "Auc: 2019-03-10 12:32:15.822291\n",
      " 0 - 1 : 0.6571, mean=0.6571\n",
      "Prepare data: 2019-03-10 12:32:16.039255\n",
      "Fit: 2019-03-10 12:32:29.179264\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 170)               18020     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 47,261\n",
      "Trainable params: 47,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 52s - loss: 0.3971 - acc: 0.8496\n",
      "Epoch 2/10\n",
      " - 50s - loss: 0.3924 - acc: 0.8497\n",
      "Epoch 3/10\n",
      " - 51s - loss: 0.3909 - acc: 0.8497\n",
      "Epoch 4/10\n",
      " - 50s - loss: 0.3901 - acc: 0.8497\n",
      "Epoch 5/10\n",
      " - 52s - loss: 0.3894 - acc: 0.8497\n",
      "Epoch 6/10\n",
      " - 51s - loss: 0.3889 - acc: 0.8497\n",
      "Epoch 7/10\n",
      " - 50s - loss: 0.3884 - acc: 0.8497\n",
      "Epoch 8/10\n",
      " - 51s - loss: 0.3880 - acc: 0.8497\n",
      "Epoch 9/10\n",
      " - 52s - loss: 0.3876 - acc: 0.8497\n",
      "Epoch 10/10\n",
      " - 52s - loss: 0.3872 - acc: 0.8497\n",
      "Starting train: 2019-03-10 12:43:30.907677\n",
      "Predict: 2019-03-10 12:47:41.014428\n",
      "Auc: 2019-03-10 12:48:45.288946\n",
      " 0 - 2 : 0.6548, mean=0.6559\n",
      "Prepare data: 2019-03-10 12:48:45.539955\n",
      "Fit: 2019-03-10 12:48:59.660946\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 170)               18020     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 47,261\n",
      "Trainable params: 47,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9efc7a625654>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(model, data, n_folds, n_iters, seed, verbose, gv)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fit: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predict: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-6ee629d48d24>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9f05934002b5>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verbose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         )\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    183\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 185\u001b[0;31m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[0m\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "cross_validation(MeanModel([KerasModel({\n",
    "    'epochs': 10,\n",
    "    'verbose': 2,\n",
    "}), LgbModel({\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_data_in_leaf': 25,\n",
    "    'lambda_l2': 0.0,\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.35,\n",
    "    'feature_fraction': 1,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'num_boost_round': 1000,\n",
    "    'verbose': 0\n",
    "})], [0.4, 0.6]), sub, n_iters=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-09 22:39:09.654425\n",
      "Fit: 2019-03-09 22:39:16.206803\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_73 (Dense)             (None, 170)               18700     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 47,941\n",
      "Trainable params: 47,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " - 55s - loss: 0.3937 - acc: 0.8508\n",
      "Epoch 2/10\n",
      " - 52s - loss: 0.3892 - acc: 0.8509\n",
      "Epoch 3/10\n",
      " - 54s - loss: 0.3878 - acc: 0.8508\n",
      "Epoch 4/10\n",
      " - 53s - loss: 0.3869 - acc: 0.8508\n",
      "Epoch 5/10\n",
      " - 52s - loss: 0.3862 - acc: 0.8508\n",
      "Epoch 6/10\n",
      " - 53s - loss: 0.3857 - acc: 0.8509\n",
      "Epoch 7/10\n",
      " - 53s - loss: 0.3852 - acc: 0.8509\n",
      "Epoch 8/10\n",
      " - 54s - loss: 0.3849 - acc: 0.8509\n",
      "Epoch 9/10\n",
      " - 54s - loss: 0.3844 - acc: 0.8509\n",
      "Epoch 10/10\n",
      " - 51s - loss: 0.3841 - acc: 0.8509\n",
      "Predict: 2019-03-09 22:48:30.076414\n",
      "Auc: 2019-03-09 22:48:50.630969\n",
      " 0 - 1 : 0.6480, mean=0.6480\n",
      "Prepare data: 2019-03-09 22:48:50.856857\n",
      "Fit: 2019-03-09 22:48:55.303075\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9efc7a625654>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(model, data, n_folds, n_iters, seed, verbose, gv)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Fit: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predict: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-d3e9ffe44127>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-ba8c27604e08>\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, inplace)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mstd\u001b[0;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[1;32m   3237\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3239\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3241\u001b[0m     return _methods._std(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, ddof, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  10974\u001b[0m                                       skipna=skipna, ddof=ddof)\n\u001b[1;32m  10975\u001b[0m         return self._reduce(f, name, axis=axis, numeric_only=numeric_only,\n\u001b[0;32m> 10976\u001b[0;31m                             skipna=skipna, ddof=ddof)\n\u001b[0m\u001b[1;32m  10977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10978\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   3624\u001b[0m                                           'numeric_only.'.format(name))\n\u001b[1;32m   3625\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3626\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3628\u001b[0m         \u001b[0;31m# TODO(EA) dispatch to Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanstd\u001b[0;34m(values, axis, skipna, ddof, mask)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \"\"\"\n\u001b[1;32m    609\u001b[0m     result = np.sqrt(nanvar(values, axis=axis, skipna=skipna, ddof=ddof,\n\u001b[0;32m--> 610\u001b[0;31m                             mask=mask))\n\u001b[0m\u001b[1;32m    611\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrap_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanvar\u001b[0;34m(values, axis, skipna, ddof, mask)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m     \u001b[0msqr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msqr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "cross_validation(KerasModel({\n",
    "    'epochs': 10,\n",
    "    'verbose': 2,\n",
    "}), sub, n_iters=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 0.0, 0.35, 1, 1000, 30)\n",
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-09 13:01:47.582152\n",
      "Fit: 2019-03-09 13:01:51.349356\n",
      "Starting train: 2019-03-09 13:01:53.752369\n",
      "Predict: 2019-03-09 13:05:47.094824\n",
      "Auc: 2019-03-09 13:06:03.430540\n",
      " 0 - 1 : 0.6498, mean=0.6498\n",
      "Prepare data: 2019-03-09 13:06:03.655497\n",
      "Fit: 2019-03-09 13:06:10.751042\n",
      "Starting train: 2019-03-09 13:06:12.187180\n",
      "Predict: 2019-03-09 13:09:57.993294\n",
      "Auc: 2019-03-09 13:10:13.762770\n",
      " 0 - 2 : 0.6485, mean=0.6491\n",
      "Prepare data: 2019-03-09 13:10:13.994431\n",
      "Fit: 2019-03-09 13:10:21.106000\n",
      "Starting train: 2019-03-09 13:10:22.502458\n",
      "Predict: 2019-03-09 13:14:10.567627\n",
      "Auc: 2019-03-09 13:14:27.225390\n",
      " 0 - 3 : 0.6486, mean=0.6490\n",
      "Prepare data: 2019-03-09 13:14:27.460103\n",
      "Fit: 2019-03-09 13:14:31.091658\n",
      "Starting train: 2019-03-09 13:14:32.705446\n",
      "Predict: 2019-03-09 13:18:35.128126\n",
      "Auc: 2019-03-09 13:18:51.722594\n",
      " 0 - 4 : 0.6504, mean=0.6493\n",
      "Prepare data: 2019-03-09 13:18:51.960068\n",
      "Fit: 2019-03-09 13:18:56.871702\n",
      "Starting train: 2019-03-09 13:18:58.241789\n",
      "Predict: 2019-03-09 13:22:56.693188\n",
      "Auc: 2019-03-09 13:23:14.132614\n",
      " 0 - 5 : 0.6516, mean=0.6498\n",
      "CPU times: user 1h 13min 2s, sys: 1min 24s, total: 1h 14min 27s\n",
      "Wall time: 21min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################################### PARTIAL TRAIN\n",
    "for min_data_in_leaf in (25,):\n",
    "    for lambda_l2 in (0.0,):\n",
    "        for learning_rate in (0.35,):\n",
    "            for feature_fraction in (1,):\n",
    "                for num_boost_round in (1000,):\n",
    "                    for num_leaves in (30,):\n",
    "                        print((min_data_in_leaf,lambda_l2,learning_rate,feature_fraction,num_boost_round,num_leaves))\n",
    "                        cross_validation(LgbModel({\n",
    "                            'boosting_type': 'gbdt',\n",
    "                            'min_data_in_leaf': min_data_in_leaf,\n",
    "                            'lambda_l2': lambda_l2,\n",
    "                            'num_leaves': num_leaves,\n",
    "                            'learning_rate': learning_rate,\n",
    "                            'feature_fraction': feature_fraction,\n",
    "                            'bagging_fraction': 1,\n",
    "                            'bagging_freq': 5,\n",
    "                            'num_boost_round': num_boost_round,\n",
    "                            #'max_depth': 4,\n",
    "                            'verbose': 0\n",
    "                        }), sub, n_iters=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 0.0, 0.35, 1, 1000, 30)\n",
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-09 17:02:47.919122\n",
      "Fit: 2019-03-09 17:03:23.356649\n",
      "Starting train: 2019-03-09 17:03:43.841102\n",
      "Predict: 2019-03-09 17:28:47.218106\n",
      "Auc: 2019-03-09 17:30:27.322895\n",
      " 0 - 1 : 0.6616, mean=0.6616\n",
      "Prepare data: 2019-03-09 17:30:28.524928\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9efc7a625654>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(model, data, n_folds, n_iters, seed, verbose, gv)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prepare data: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstanceId_userId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstanceId_userId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mgv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_train'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2916\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2920\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2967\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[1;32m   3357\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   3358\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3359\u001b[0;31m                                    verify=True)\n\u001b[0m\u001b[1;32m   3360\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 1350\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   1234\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 1235\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   1234\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 1235\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1236\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1238\u001b[0;31m                                        allow_fill=True, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n\u001b[1;32m   1648\u001b[0m                                  mask_info=mask_info)\n\u001b[0;32m-> 1649\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for min_data_in_leaf in (25,):\n",
    "    for lambda_l2 in (0.0,):\n",
    "        for learning_rate in (0.35,):\n",
    "            for feature_fraction in (1,):\n",
    "                for num_boost_round in (1000,):\n",
    "                    for num_leaves in (30,):\n",
    "                        print((min_data_in_leaf,lambda_l2,learning_rate,feature_fraction,num_boost_round,num_leaves))\n",
    "                        cross_validation(LgbModel({\n",
    "                            'boosting_type': 'gbdt',\n",
    "                            'min_data_in_leaf': min_data_in_leaf,\n",
    "                            'lambda_l2': lambda_l2,\n",
    "                            'num_leaves': num_leaves,\n",
    "                            'learning_rate': learning_rate,\n",
    "                            'feature_fraction': feature_fraction,\n",
    "                            'bagging_fraction': 1,\n",
    "                            'bagging_freq': 5,\n",
    "                            'num_boost_round': num_boost_round,\n",
    "                            #'max_depth': 4,\n",
    "                            'verbose': 0\n",
    "                        }), train, n_iters=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_texts_features\n",
    "del test_texts_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation(SimpleModel({\n",
    "    'activation': 'relu',\n",
    "    'alpha': 0.0002, \n",
    "    'hidden_layer_sizes': (20,10),\n",
    "    'max_iter': 150,\n",
    "    'learning_rate_init': 0.001,\n",
    "    'random_state': 322,\n",
    "}), train[train.instanceId_userId % 4 == 0], n_iters=1, verbose=2)\n",
    "#0 - 1 : 0.6302, mean=0.6302\n",
    "#0 - 2 : 0.6340, mean=0.6321\n",
    "#0 - 3 : 0.6336, mean=0.6326\n",
    "#0 - 4 : 0.6349, mean=0.6332\n",
    "#0 - 5 : 0.6355, mean=0.6336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validation(SimpleModel({\n",
    "    'activation': 'relu',\n",
    "    'alpha': 0.0002, \n",
    "    'hidden_layer_sizes': (20,10),\n",
    "    'max_iter': 150,\n",
    "    'learning_rate_init': 0.001,\n",
    "    'random_state': 322,\n",
    "}), train, n_iters=1, verbose=2)\n",
    "#0 - 1 : 0.6343, mean=0.6343\n",
    "#0 - 2 : 0.6350, mean=0.6347\n",
    "#0 - 3 : 0.6336, mean=0.6343\n",
    "#0 - 4 : 0.6362, mean=0.6348\n",
    "#0 - 5 : 0.6335, mean=0.6345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-03 12:55:49.726751\n",
      "Fit: 2019-03-03 12:55:53.899066\n",
      "Starting train: 2019-03-03 13:00:23.640107\n",
      "Predict: 2019-03-03 13:02:31.636356\n",
      "Auc: 2019-03-03 13:02:43.630157\n",
      " 0 - 1 : 0.6428, mean=0.6428\n",
      "Prepare data: 2019-03-03 13:02:43.869736\n",
      "Fit: 2019-03-03 13:02:48.432884\n",
      "Starting train: 2019-03-03 13:06:03.138844\n",
      "Predict: 2019-03-03 13:07:56.479731\n",
      "Auc: 2019-03-03 13:08:07.760857\n",
      " 0 - 2 : 0.6485, mean=0.6457\n",
      "Prepare data: 2019-03-03 13:08:08.008444\n",
      "Fit: 2019-03-03 13:08:11.709497\n",
      "Starting train: 2019-03-03 13:12:29.351229\n",
      "Predict: 2019-03-03 13:14:32.795332\n",
      "Auc: 2019-03-03 13:14:44.816287\n",
      " 0 - 3 : 0.6465, mean=0.6460\n",
      "Prepare data: 2019-03-03 13:14:45.087854\n",
      "Fit: 2019-03-03 13:14:50.995079\n",
      "Starting train: 2019-03-03 13:19:37.795959\n",
      "Predict: 2019-03-03 13:21:48.386645\n",
      "Auc: 2019-03-03 13:21:59.751583\n",
      " 0 - 4 : 0.6469, mean=0.6462\n",
      "Prepare data: 2019-03-03 13:21:59.997758\n",
      "Fit: 2019-03-03 13:22:04.246438\n",
      "Starting train: 2019-03-03 13:26:13.814206\n",
      "Predict: 2019-03-03 13:28:12.869495\n",
      "Auc: 2019-03-03 13:28:24.096229\n",
      " 0 - 5 : 0.6464, mean=0.6462\n"
     ]
    }
   ],
   "source": [
    "cross_validation(MeanModel([SimpleModel({\n",
    "    'activation': 'relu',\n",
    "    'alpha': 0.0002, \n",
    "    'hidden_layer_sizes': (20,10),\n",
    "    'max_iter': 150,\n",
    "    'learning_rate_init': 0.001,\n",
    "    'random_state': 322,\n",
    "}), LgbModel({\n",
    "    #'num_threads': 4,\n",
    "    #'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_data_in_leaf': min_data_in_leaf,\n",
    "    'lambda_l2': lambda_l2,\n",
    "    'num_leaves': num_leaves,\n",
    "    'learning_rate': learning_rate,\n",
    "    'feature_fraction': feature_fraction,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'num_boost_round': num_boost_round,\n",
    "    #'max_depth': 4,\n",
    "    'verbose': 0\n",
    "})], [0.2, 0.8]), train[train.instanceId_userId % 4 == 0], n_iters=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-03 13:37:44.297815\n",
      "Fit: 2019-03-03 13:38:15.259374\n",
      "Starting train: 2019-03-03 13:54:29.038383\n",
      "Predict: 2019-03-03 14:02:46.777934\n",
      "Auc: 2019-03-03 14:03:33.764797\n",
      " 0 - 1 : 0.6546, mean=0.6546\n",
      "Prepare data: 2019-03-03 14:03:34.858943\n",
      "Fit: 2019-03-03 14:04:05.008568\n",
      "Starting train: 2019-03-03 14:21:08.876929\n",
      "Predict: 2019-03-03 14:29:55.398157\n",
      "Auc: 2019-03-03 14:30:40.288930\n",
      " 0 - 2 : 0.6551, mean=0.6549\n",
      "Prepare data: 2019-03-03 14:30:41.454805\n",
      "Fit: 2019-03-03 14:31:11.550560\n",
      "Starting train: 2019-03-03 14:46:05.297896\n",
      "Predict: 2019-03-03 14:54:45.267508\n",
      "Auc: 2019-03-03 14:55:32.654440\n",
      " 0 - 3 : 0.6540, mean=0.6546\n",
      "Prepare data: 2019-03-03 14:55:33.804110\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-447aff7ea09f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#'max_depth': 4,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m'verbose'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m })], [0.2, 0.8]), train, n_iters=1, verbose=2)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-138-b43944772e3d>\u001b[0m in \u001b[0;36mcross_validation\u001b[0;34m(model, data, n_folds, n_iters, seed, verbose)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prepare data: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstanceId_userId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mdata_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstanceId_userId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2916\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2920\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2967\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, is_copy)\u001b[0m\n\u001b[1;32m   3357\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   3358\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3359\u001b[0;31m                                    verify=True)\n\u001b[0m\u001b[1;32m   3360\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 1350\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   1234\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 1235\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1233\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   1234\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 1235\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   1236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_tuple)\u001b[0m\n\u001b[1;32m   1236\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m             new_values = algos.take_nd(values, indexer, axis=axis,\n\u001b[0;32m-> 1238\u001b[0;31m                                        allow_fill=True, fill_value=fill_value)\n\u001b[0m\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n\u001b[1;32m   1648\u001b[0m                                  mask_info=mask_info)\n\u001b[0;32m-> 1649\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cross_validation(MeanModel([SimpleModel({\n",
    "    'activation': 'relu',\n",
    "    'alpha': 0.0002, \n",
    "    'hidden_layer_sizes': (20,10),\n",
    "    'max_iter': 150,\n",
    "    'learning_rate_init': 0.001,\n",
    "    'random_state': 322,\n",
    "}), LgbModel({\n",
    "    #'num_threads': 4,\n",
    "    #'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_data_in_leaf': min_data_in_leaf,\n",
    "    'lambda_l2': lambda_l2,\n",
    "    'num_leaves': num_leaves,\n",
    "    'learning_rate': learning_rate,\n",
    "    'feature_fraction': feature_fraction,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'num_boost_round': num_boost_round,\n",
    "    #'max_depth': 4,\n",
    "    'verbose': 0\n",
    "})], [0.2, 0.8]), train, n_iters=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=2707, shuffle=True)\n",
      "Prepare data: 2019-03-03 12:20:16.209874\n",
      "Fit: 2019-03-03 12:20:49.620798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int8, int64, float32, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:22: DataConversionWarning: Data with input dtype int8, int64, float32, float64 were all converted to float64 by StandardScaler.\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: 2019-03-03 12:23:28.459235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-126-e5ee90825de5>\", line 8, in <module>\n",
      "    }), train, n_iters=1, verbose=2)\n",
      "  File \"<ipython-input-103-b43944772e3d>\", line 20, in cross_validation\n",
      "    pred = model.predict(data_test.drop('label', 1))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\", line 3940, in drop\n",
      "    errors=errors)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\", line 3780, in drop\n",
      "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\", line 3813, in _drop_axis\n",
      "    result = self.reindex(**{axis_name: new_axis})\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/util/_decorators.py\", line 197, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\", line 3809, in reindex\n",
      "    return super(DataFrame, self).reindex(**kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\", line 4356, in reindex\n",
      "    fill_value, copy).__finalize__(self)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\", line 3736, in _reindex_axes\n",
      "    fill_value, limit, tolerance)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\", line 3761, in _reindex_columns\n",
      "    allow_dups=False)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/generic.py\", line 4490, in _reindex_with_indexers\n",
      "    copy=copy)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1231, in reindex_indexer\n",
      "    fill_tuple=(fill_value,))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1312, in _slice_take_blocks_ax0\n",
      "    fill_tuple=None))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 1234, in take_nd\n",
      "    allow_fill=False, fill_value=fill_value)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/pandas/core/algorithms.py\", line 1649, in take_nd\n",
      "    func(arr, indexer, out, fill_value)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/local/Cellar/python/3.7.2_2/Frameworks/Python.framework/Versions/3.7/lib/python3.7/inspect.py\", line 732, in getmodule\n",
      "    for modname, module in list(sys.modules.items()):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_validation(SimpleModel({\n",
    "    'activation': 'relu',\n",
    "    'alpha': 0.0002, \n",
    "    'hidden_layer_sizes': (30,15),\n",
    "    'max_iter': 150,\n",
    "    'learning_rate_init': 0.001,\n",
    "    'random_state': 322,\n",
    "}), train, n_iters=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    1618,     2122,   405739, ..., 15717307, 15717313, 15717370],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((train.instanceId_userId.values, test.instanceId_userId.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "#plt.hist(train.instanceId_userId.values, 50, color='blue', alpha=0.5, stacked=True)\n",
    "plt.hist(test.instanceId_userId.values, 50, color='red', alpha=0.5, stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12, 9) # (w, h)\n",
    "stat = train.groupby('instanceId_userId').agg({'objectId': 'count'}).reset_index()\n",
    "stat['objectId'].clip(upper=400, inplace=True)\n",
    "x = stat.instanceId_userId.values\n",
    "y = stat.objectId.values\n",
    "plt.plot(stat.instanceId_userId.values, stat.objectId.values, marker='o', color='r', ls='')\n",
    "a, b = np.polyfit(x, y, deg=1)\n",
    "f = lambda x: a*x + b\n",
    "plt.plot([min(x), max(x)],[f(min(x)), f(max(x))], c=\"orange\", label=\"---\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 15716692], [4.675623173024054, 6.05310121218764])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[min(x), max(x)],[f(min(x)), f(max(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [-0.10615078, -0.010773562, -0.56575644, -0.12...\n",
       "1          [-0.0683545, 0.07140685, -0.20106804, 0.104985...\n",
       "2          [-0.02723738, 0.06277889, -0.43565413, 0.18430...\n",
       "3          [0.045580994, 0.040244624, -0.6059874, 0.25647...\n",
       "4          [0.0032542336, 0.014345958, 0.0068508917, 0.00...\n",
       "5          [-0.08434731, 0.44924405, -0.11457637, 0.18142...\n",
       "6          [0.054944713, -0.016345793, -0.20541555, 0.053...\n",
       "7          [0.058710147, -0.04227986, -0.21007676, 0.0421...\n",
       "8          [-0.007924212, 0.023569267, -0.40307418, 0.166...\n",
       "9          [0.0017259811, -0.04990819, -0.4736356, 0.1148...\n",
       "10         [-0.09405366, 0.13276497, -0.51096237, 0.12392...\n",
       "11         [0.07896449, -0.015920404, -0.2127133, 0.10028...\n",
       "12         [-0.72267175, 0.2736861, -0.6084051, -0.400014...\n",
       "13         [-0.037868008, 0.30197683, -0.45972252, 0.3364...\n",
       "14         [0.0309244, 0.04448738, -0.21612203, 0.0947049...\n",
       "15         [-0.019892128, 0.058245588, -0.3105936, 0.0849...\n",
       "16         [0.0032542336, 0.014345958, 0.0068508917, 0.00...\n",
       "17         [-0.035130408, 0.08970725, -0.6928831, 0.05795...\n",
       "18         [-0.028063392, -0.010307665, -0.09504826, 0.03...\n",
       "19         [-0.0478124, -0.03633474, -0.17741123, 0.11296...\n",
       "20         [0.01392984, -0.026965344, -0.17611262, 0.0753...\n",
       "21         [-7.738533e-05, -0.022733249, -0.21509312, 0.0...\n",
       "22         [0.014936621, 0.12797758, -0.6418327, 0.122551...\n",
       "23         [0.031678673, -0.04248926, -0.16077526, 0.1199...\n",
       "24         [-0.10695773, 0.0790177, -0.8278927, -0.077654...\n",
       "25         [0.12717423, -0.05631348, -0.2909909, 0.313064...\n",
       "26         [0.015539164, -0.0201548, -0.09919848, 0.02632...\n",
       "27         [-0.0098532885, 0.00014208633, -0.5842666, 0.1...\n",
       "28         [-0.085025504, -0.008173506, -0.4256819, 0.101...\n",
       "29         [0.00052364956, 0.1435759, -1.1167803, 0.88964...\n",
       "                                 ...                        \n",
       "3410886    [0.013255284, -0.011659173, -0.16302243, 0.046...\n",
       "3410887    [-0.013502174, -0.010192932, -0.023316119, 0.0...\n",
       "3410888    [-0.030085534, -0.053638298, -0.34885228, 0.07...\n",
       "3410889    [-0.015756454, -0.026203914, -0.16268292, 0.08...\n",
       "3410890    [-0.015702896, -0.007563768, -0.12755993, 0.01...\n",
       "3410891    [0.008304376, -0.04738779, -0.31983417, 0.1557...\n",
       "3410892    [0.0032542336, 0.014345958, 0.0068508917, 0.00...\n",
       "3410893    [-0.041549545, 0.21023741, -0.2950924, 0.11583...\n",
       "3410894    [0.041244056, 0.07055152, -0.5272733, 0.286025...\n",
       "3410895    [-0.024514593, -0.00026945033, -0.514837, 0.19...\n",
       "3410896    [0.0032542336, 0.014345958, 0.0068508917, 0.00...\n",
       "3410897    [0.14852278, 0.19555369, -0.21039984, 0.599955...\n",
       "3410898    [0.05823364, -0.035046216, -0.24449097, 0.1535...\n",
       "3410899    [-0.1989169, 0.08814779, -0.6624839, -0.140460...\n",
       "3410900    [0.071110845, 0.006018173, -0.29451355, 0.1125...\n",
       "3410901    [-0.04751115, 0.08626335, -0.6670576, 0.496033...\n",
       "3410902    [0.90393406, 1.2090584, -1.6729603, 0.6039948,...\n",
       "3410903    [0.030192701, 0.021585278, -0.17314087, 0.0116...\n",
       "3410904    [-0.5094605, 0.3478111, -0.5692532, -0.3806071...\n",
       "3410905    [-0.034675635, -0.003100829, -0.28676933, 0.01...\n",
       "3410906    [-0.011343256, 0.057197217, -0.0870824, 0.0379...\n",
       "3410907    [-0.033308245, 0.008128116, -0.075155504, 0.02...\n",
       "3410908    [-0.026452586, 0.17674607, -0.59629375, 0.2911...\n",
       "3410909    [-0.10569848, 0.033905666, -0.4723223, 0.06614...\n",
       "3410910    [0.009205608, -0.021814989, -0.6020374, 0.0821...\n",
       "3410911    [0.010752049, -0.00899232, -0.06926036, 0.0740...\n",
       "3410912    [-0.6232079, 0.23327334, -0.5671713, -0.379394...\n",
       "3410913    [0.029712327, -0.0025838732, -0.21409824, 0.11...\n",
       "3410914    [-0.046451, -0.029189574, -0.5131265, 0.088671...\n",
       "3410915    [0.06923902, -0.06598932, -0.4233043, 0.209294...\n",
       "Name: embedding, Length: 3410916, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts_features.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "kclusterer = KMeansClusterer(3, distance=nltk.cluster.util.cosine_distance, repeats=50)\n",
    "assigned_clusters3_50 = kclusterer.cluster(\n",
    "    np.concatenate((train_texts_features.embedding, test_texts_features.embedding)), assign_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "kclusterer = KMeansClusterer(6, distance=nltk.cluster.util.cosine_distance, repeats=25, avoid_empty_clusters=True)\n",
    "assigned_clusters6_25 = kclusterer.cluster(\n",
    "    np.concatenate((train_texts_features.embedding, test_texts_features.embedding)), assign_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/nltk/cluster/util.py:133: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - (numpy.dot(u, v) / (sqrt(numpy.dot(u, u)) * sqrt(numpy.dot(v, v))))\n",
      "/usr/local/lib/python3.7/site-packages/nltk/cluster/util.py:133: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 1 - (numpy.dot(u, v) / (sqrt(numpy.dot(u, u)) * sqrt(numpy.dot(v, v))))\n",
      "Error: no centroid defined for empty cluster.\n",
      "Try setting argument 'avoid_empty_clusters' to True\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-16ef8a8f9884>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkclusterer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeansClusterer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m assigned_clusters4_10 = kclusterer.cluster(\n\u001b[0;32m----> 3\u001b[0;31m     np.concatenate((train_texts_features.embedding, test_texts_features.embedding)), assign_clusters=True)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/cluster/util.py\u001b[0m in \u001b[0;36mcluster\u001b[0;34m(self, vectors, assign_clusters, trace)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# call abstract method to cluster the vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_vectorspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# assign the vectors to clusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/cluster/kmeans.py\u001b[0m in \u001b[0;36mcluster_vectorspace\u001b[0;34m(self, vectors, trace)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_means\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cluster_vectorspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mmeanss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/cluster/kmeans.py\u001b[0m in \u001b[0;36m_cluster_vectorspace\u001b[0;34m(self, vectors, trace)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;31m# recalculate cluster means by computing the centroid of each cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mnew_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_centroid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;31m# measure the degree of change from the previous step for convergence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/nltk/cluster/kmeans.py\u001b[0m in \u001b[0;36m_centroid\u001b[0;34m(self, cluster, mean)\u001b[0m\n\u001b[1;32m    183\u001b[0m                     \u001b[0;34m'Try setting argument \\'avoid_empty_clusters\\' to True\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 )\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0mcentroid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kclusterer = KMeansClusterer(4, distance=nltk.cluster.util.cosine_distance, repeats=10)\n",
    "assigned_clusters4_10 = kclusterer.cluster(\n",
    "    np.concatenate((train_texts_features.embedding, test_texts_features.embedding)), assign_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_features['assigned_clusters'] = assigned_clusters6_25[0:train_texts_features.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'assigned_clusters3_50': assigned_clusters3_50}).to_pickle(output_path + '/assigned_clusters3_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instanceId_userId</th>\n",
       "      <th>instanceId_objectType</th>\n",
       "      <th>objectId</th>\n",
       "      <th>audit_clientType</th>\n",
       "      <th>audit_timestamp</th>\n",
       "      <th>metadata_ownerId</th>\n",
       "      <th>metadata_createdAt</th>\n",
       "      <th>date</th>\n",
       "      <th>liked</th>\n",
       "      <th>clicked</th>\n",
       "      <th>...</th>\n",
       "      <th>ok_groups_count</th>\n",
       "      <th>is_adv</th>\n",
       "      <th>is_recipe</th>\n",
       "      <th>hashes_count</th>\n",
       "      <th>quotes_count</th>\n",
       "      <th>mdots_count</th>\n",
       "      <th>brackets_balance</th>\n",
       "      <th>has_phone</th>\n",
       "      <th>is_poll</th>\n",
       "      <th>e_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1618</td>\n",
       "      <td>0</td>\n",
       "      <td>25814780</td>\n",
       "      <td>0</td>\n",
       "      <td>1517458217938</td>\n",
       "      <td>81088</td>\n",
       "      <td>1517454825000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2122</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517488844356</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>405739</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>2</td>\n",
       "      <td>1517511247948</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>659725</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>0</td>\n",
       "      <td>1517466559543</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4836</th>\n",
       "      <td>1748401</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517511622831</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6826</th>\n",
       "      <td>2404081</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517487632489</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8062</th>\n",
       "      <td>2796664</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>0</td>\n",
       "      <td>1517452044806</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12652</th>\n",
       "      <td>4257952</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517433315078</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18474</th>\n",
       "      <td>6000712</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>2</td>\n",
       "      <td>1517459635654</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19276</th>\n",
       "      <td>6265702</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517509974847</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26749</th>\n",
       "      <td>8336428</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517483005214</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30506</th>\n",
       "      <td>9321607</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517479026714</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32108</th>\n",
       "      <td>9747073</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>0</td>\n",
       "      <td>1517474492137</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41929</th>\n",
       "      <td>12359680</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>2</td>\n",
       "      <td>1517473317899</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47045</th>\n",
       "      <td>13806016</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517477586365</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51833</th>\n",
       "      <td>15163702</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>0</td>\n",
       "      <td>1517496115448</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53705</th>\n",
       "      <td>23812</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517486319604</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54208</th>\n",
       "      <td>250168</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>0</td>\n",
       "      <td>1517437682563</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57957</th>\n",
       "      <td>1544983</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>0</td>\n",
       "      <td>1517484407125</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58881</th>\n",
       "      <td>1852279</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517497780794</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64069</th>\n",
       "      <td>3573316</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517481290417</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83005</th>\n",
       "      <td>9081523</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>0</td>\n",
       "      <td>1517446429182</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109520</th>\n",
       "      <td>884068</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517505196799</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111763</th>\n",
       "      <td>1691746</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>0</td>\n",
       "      <td>1517501026144</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112265</th>\n",
       "      <td>1887535</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>0</td>\n",
       "      <td>1517461680439</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113358</th>\n",
       "      <td>2281477</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517488224440</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113648</th>\n",
       "      <td>2378962</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>2</td>\n",
       "      <td>1517472928093</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114134</th>\n",
       "      <td>2533057</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517474526190</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116453</th>\n",
       "      <td>3307621</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517437985575</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118080</th>\n",
       "      <td>3833293</td>\n",
       "      <td>0</td>\n",
       "      <td>10027037</td>\n",
       "      <td>1</td>\n",
       "      <td>1517439934000</td>\n",
       "      <td>4016</td>\n",
       "      <td>1517423778000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6766</td>\n",
       "      <td>0</td>\n",
       "      <td>21321981</td>\n",
       "      <td>0</td>\n",
       "      <td>1517516528103</td>\n",
       "      <td>48585</td>\n",
       "      <td>1517510413000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262731</th>\n",
       "      <td>14455618</td>\n",
       "      <td>0</td>\n",
       "      <td>21321981</td>\n",
       "      <td>2</td>\n",
       "      <td>1517511874335</td>\n",
       "      <td>48585</td>\n",
       "      <td>1517510413000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643915</th>\n",
       "      <td>15517480</td>\n",
       "      <td>0</td>\n",
       "      <td>21321981</td>\n",
       "      <td>0</td>\n",
       "      <td>1517520771146</td>\n",
       "      <td>48585</td>\n",
       "      <td>1517510413000</td>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7171</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>1</td>\n",
       "      <td>1517453332666</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6760</th>\n",
       "      <td>2379646</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>0</td>\n",
       "      <td>1517505634224</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13390</th>\n",
       "      <td>4490920</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>1</td>\n",
       "      <td>1517467691224</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21137</th>\n",
       "      <td>6803098</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>0</td>\n",
       "      <td>1517480389435</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26635</th>\n",
       "      <td>8306323</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>1</td>\n",
       "      <td>1517464144699</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40423</th>\n",
       "      <td>11973352</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>1</td>\n",
       "      <td>1517504480449</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59812</th>\n",
       "      <td>2177431</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>1</td>\n",
       "      <td>1517496820369</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71361</th>\n",
       "      <td>5815510</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>1</td>\n",
       "      <td>1517479937245</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75174</th>\n",
       "      <td>6887560</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>0</td>\n",
       "      <td>1517471939244</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77053</th>\n",
       "      <td>7436146</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>0</td>\n",
       "      <td>1517497060538</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81625</th>\n",
       "      <td>8710573</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>1</td>\n",
       "      <td>1517472258633</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84628</th>\n",
       "      <td>9541996</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>1</td>\n",
       "      <td>1517512840440</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93824</th>\n",
       "      <td>11981962</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>0</td>\n",
       "      <td>1517450275853</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99406</th>\n",
       "      <td>13504378</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>1</td>\n",
       "      <td>1517473058137</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113631</th>\n",
       "      <td>2373196</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>0</td>\n",
       "      <td>1517497090328</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117672</th>\n",
       "      <td>3717145</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>1</td>\n",
       "      <td>1517488849752</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126162</th>\n",
       "      <td>6293401</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>0</td>\n",
       "      <td>1517466728015</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139009</th>\n",
       "      <td>9801781</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>0</td>\n",
       "      <td>1517490466575</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147781</th>\n",
       "      <td>12149818</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>0</td>\n",
       "      <td>1517486667538</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149708</th>\n",
       "      <td>12678094</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>0</td>\n",
       "      <td>1517507900591</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157348</th>\n",
       "      <td>14787397</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>2</td>\n",
       "      <td>1517513916424</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165271</th>\n",
       "      <td>1764694</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>1</td>\n",
       "      <td>1517508476766</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199144</th>\n",
       "      <td>11609959</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>1</td>\n",
       "      <td>1517508431328</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218418</th>\n",
       "      <td>1707196</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>0</td>\n",
       "      <td>1517472341578</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219280</th>\n",
       "      <td>2011723</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>0</td>\n",
       "      <td>1517493037934</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220786</th>\n",
       "      <td>2498575</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>0</td>\n",
       "      <td>1517499403981</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255584</th>\n",
       "      <td>12471343</td>\n",
       "      <td>0</td>\n",
       "      <td>22914726</td>\n",
       "      <td>1</td>\n",
       "      <td>1517469563912</td>\n",
       "      <td>25904</td>\n",
       "      <td>1517323225000</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        instanceId_userId  instanceId_objectType  objectId  audit_clientType  \\\n",
       "0                    1618                      0  25814780                 0   \n",
       "1                    2122                      0  10027037                 1   \n",
       "1070               405739                      0  10027037                 2   \n",
       "1759               659725                      0  10027037                 0   \n",
       "4836              1748401                      0  10027037                 1   \n",
       "6826              2404081                      0  10027037                 1   \n",
       "8062              2796664                      0  10027037                 0   \n",
       "12652             4257952                      0  10027037                 1   \n",
       "18474             6000712                      0  10027037                 2   \n",
       "19276             6265702                      0  10027037                 1   \n",
       "26749             8336428                      0  10027037                 1   \n",
       "30506             9321607                      0  10027037                 1   \n",
       "32108             9747073                      0  10027037                 0   \n",
       "41929            12359680                      0  10027037                 2   \n",
       "47045            13806016                      0  10027037                 1   \n",
       "51833            15163702                      0  10027037                 0   \n",
       "53705               23812                      0  10027037                 1   \n",
       "54208              250168                      0  10027037                 0   \n",
       "57957             1544983                      0  10027037                 0   \n",
       "58881             1852279                      0  10027037                 1   \n",
       "64069             3573316                      0  10027037                 1   \n",
       "83005             9081523                      0  10027037                 0   \n",
       "109520             884068                      0  10027037                 1   \n",
       "111763            1691746                      0  10027037                 0   \n",
       "112265            1887535                      0  10027037                 0   \n",
       "113358            2281477                      0  10027037                 1   \n",
       "113648            2378962                      0  10027037                 2   \n",
       "114134            2533057                      0  10027037                 1   \n",
       "116453            3307621                      0  10027037                 1   \n",
       "118080            3833293                      0  10027037                 1   \n",
       "...                   ...                    ...       ...               ...   \n",
       "8                    6766                      0  21321981                 0   \n",
       "262731           14455618                      0  21321981                 2   \n",
       "643915           15517480                      0  21321981                 0   \n",
       "9                    7171                      0  22914726                 1   \n",
       "6760              2379646                      0  22914726                 0   \n",
       "13390             4490920                      0  22914726                 1   \n",
       "21137             6803098                      0  22914726                 0   \n",
       "26635             8306323                      0  22914726                 1   \n",
       "40423            11973352                      0  22914726                 1   \n",
       "59812             2177431                      0  22914726                 1   \n",
       "71361             5815510                      0  22914726                 1   \n",
       "75174             6887560                      0  22914726                 0   \n",
       "77053             7436146                      0  22914726                 0   \n",
       "81625             8710573                      0  22914726                 1   \n",
       "84628             9541996                      0  22914726                 1   \n",
       "93824            11981962                      0  22914726                 0   \n",
       "99406            13504378                      0  22914726                 1   \n",
       "113631            2373196                      0  22914726                 0   \n",
       "117672            3717145                      0  22914726                 1   \n",
       "126162            6293401                      0  22914726                 0   \n",
       "139009            9801781                      0  22914726                 0   \n",
       "147781           12149818                      0  22914726                 0   \n",
       "149708           12678094                      0  22914726                 0   \n",
       "157348           14787397                      0  22914726                 2   \n",
       "165271            1764694                      0  22914726                 1   \n",
       "199144           11609959                      0  22914726                 1   \n",
       "218418            1707196                      0  22914726                 0   \n",
       "219280            2011723                      0  22914726                 0   \n",
       "220786            2498575                      0  22914726                 0   \n",
       "255584           12471343                      0  22914726                 1   \n",
       "\n",
       "        audit_timestamp  metadata_ownerId  metadata_createdAt        date  \\\n",
       "0         1517458217938             81088       1517454825000  2018-02-01   \n",
       "1         1517488844356              4016       1517423778000  2018-02-01   \n",
       "1070      1517511247948              4016       1517423778000  2018-02-01   \n",
       "1759      1517466559543              4016       1517423778000  2018-02-01   \n",
       "4836      1517511622831              4016       1517423778000  2018-02-01   \n",
       "6826      1517487632489              4016       1517423778000  2018-02-01   \n",
       "8062      1517452044806              4016       1517423778000  2018-02-01   \n",
       "12652     1517433315078              4016       1517423778000  2018-02-01   \n",
       "18474     1517459635654              4016       1517423778000  2018-02-01   \n",
       "19276     1517509974847              4016       1517423778000  2018-02-01   \n",
       "26749     1517483005214              4016       1517423778000  2018-02-01   \n",
       "30506     1517479026714              4016       1517423778000  2018-02-01   \n",
       "32108     1517474492137              4016       1517423778000  2018-02-01   \n",
       "41929     1517473317899              4016       1517423778000  2018-02-01   \n",
       "47045     1517477586365              4016       1517423778000  2018-02-01   \n",
       "51833     1517496115448              4016       1517423778000  2018-02-01   \n",
       "53705     1517486319604              4016       1517423778000  2018-02-01   \n",
       "54208     1517437682563              4016       1517423778000  2018-02-01   \n",
       "57957     1517484407125              4016       1517423778000  2018-02-01   \n",
       "58881     1517497780794              4016       1517423778000  2018-02-01   \n",
       "64069     1517481290417              4016       1517423778000  2018-02-01   \n",
       "83005     1517446429182              4016       1517423778000  2018-02-01   \n",
       "109520    1517505196799              4016       1517423778000  2018-02-01   \n",
       "111763    1517501026144              4016       1517423778000  2018-02-01   \n",
       "112265    1517461680439              4016       1517423778000  2018-02-01   \n",
       "113358    1517488224440              4016       1517423778000  2018-02-01   \n",
       "113648    1517472928093              4016       1517423778000  2018-02-01   \n",
       "114134    1517474526190              4016       1517423778000  2018-02-01   \n",
       "116453    1517437985575              4016       1517423778000  2018-02-01   \n",
       "118080    1517439934000              4016       1517423778000  2018-02-01   \n",
       "...                 ...               ...                 ...         ...   \n",
       "8         1517516528103             48585       1517510413000  2018-02-01   \n",
       "262731    1517511874335             48585       1517510413000  2018-02-01   \n",
       "643915    1517520771146             48585       1517510413000  2018-02-02   \n",
       "9         1517453332666             25904       1517323225000  2018-02-01   \n",
       "6760      1517505634224             25904       1517323225000  2018-02-01   \n",
       "13390     1517467691224             25904       1517323225000  2018-02-01   \n",
       "21137     1517480389435             25904       1517323225000  2018-02-01   \n",
       "26635     1517464144699             25904       1517323225000  2018-02-01   \n",
       "40423     1517504480449             25904       1517323225000  2018-02-01   \n",
       "59812     1517496820369             25904       1517323225000  2018-02-01   \n",
       "71361     1517479937245             25904       1517323225000  2018-02-01   \n",
       "75174     1517471939244             25904       1517323225000  2018-02-01   \n",
       "77053     1517497060538             25904       1517323225000  2018-02-01   \n",
       "81625     1517472258633             25904       1517323225000  2018-02-01   \n",
       "84628     1517512840440             25904       1517323225000  2018-02-01   \n",
       "93824     1517450275853             25904       1517323225000  2018-02-01   \n",
       "99406     1517473058137             25904       1517323225000  2018-02-01   \n",
       "113631    1517497090328             25904       1517323225000  2018-02-01   \n",
       "117672    1517488849752             25904       1517323225000  2018-02-01   \n",
       "126162    1517466728015             25904       1517323225000  2018-02-01   \n",
       "139009    1517490466575             25904       1517323225000  2018-02-01   \n",
       "147781    1517486667538             25904       1517323225000  2018-02-01   \n",
       "149708    1517507900591             25904       1517323225000  2018-02-01   \n",
       "157348    1517513916424             25904       1517323225000  2018-02-01   \n",
       "165271    1517508476766             25904       1517323225000  2018-02-01   \n",
       "199144    1517508431328             25904       1517323225000  2018-02-01   \n",
       "218418    1517472341578             25904       1517323225000  2018-02-01   \n",
       "219280    1517493037934             25904       1517323225000  2018-02-01   \n",
       "220786    1517499403981             25904       1517323225000  2018-02-01   \n",
       "255584    1517469563912             25904       1517323225000  2018-02-01   \n",
       "\n",
       "        liked  clicked  ...  ok_groups_count  is_adv  is_recipe  hashes_count  \\\n",
       "0           0        1  ...                0       0          0             0   \n",
       "1           0        0  ...                0       0          1             0   \n",
       "1070        0        0  ...                0       0          1             0   \n",
       "1759        0        0  ...                0       0          1             0   \n",
       "4836        0        0  ...                0       0          1             0   \n",
       "6826        0        0  ...                0       0          1             0   \n",
       "8062        0        1  ...                0       0          1             0   \n",
       "12652       0        0  ...                0       0          1             0   \n",
       "18474       1        0  ...                0       0          1             0   \n",
       "19276       0        1  ...                0       0          1             0   \n",
       "26749       0        0  ...                0       0          1             0   \n",
       "30506       0        0  ...                0       0          1             0   \n",
       "32108       0        0  ...                0       0          1             0   \n",
       "41929       1        0  ...                0       0          1             0   \n",
       "47045       0        0  ...                0       0          1             0   \n",
       "51833       0        0  ...                0       0          1             0   \n",
       "53705       0        0  ...                0       0          1             0   \n",
       "54208       0        0  ...                0       0          1             0   \n",
       "57957       0        0  ...                0       0          1             0   \n",
       "58881       0        0  ...                0       0          1             0   \n",
       "64069       0        0  ...                0       0          1             0   \n",
       "83005       0        0  ...                0       0          1             0   \n",
       "109520      0        0  ...                0       0          1             0   \n",
       "111763      0        0  ...                0       0          1             0   \n",
       "112265      0        0  ...                0       0          1             0   \n",
       "113358      0        0  ...                0       0          1             0   \n",
       "113648      0        0  ...                0       0          1             0   \n",
       "114134      0        1  ...                0       0          1             0   \n",
       "116453      0        0  ...                0       0          1             0   \n",
       "118080      0        0  ...                0       0          1             0   \n",
       "...       ...      ...  ...              ...     ...        ...           ...   \n",
       "8           0        0  ...                0       0          0             0   \n",
       "262731      0        0  ...                0       0          0             0   \n",
       "643915      0        0  ...                0       0          0             0   \n",
       "9           0        0  ...                0       0          1             0   \n",
       "6760        0        0  ...                0       0          1             0   \n",
       "13390       0        0  ...                0       0          1             0   \n",
       "21137       0        0  ...                0       0          1             0   \n",
       "26635       0        1  ...                0       0          1             0   \n",
       "40423       0        0  ...                0       0          1             0   \n",
       "59812       0        0  ...                0       0          1             0   \n",
       "71361       0        0  ...                0       0          1             0   \n",
       "75174       0        1  ...                0       0          1             0   \n",
       "77053       0        0  ...                0       0          1             0   \n",
       "81625       0        0  ...                0       0          1             0   \n",
       "84628       0        0  ...                0       0          1             0   \n",
       "93824       0        0  ...                0       0          1             0   \n",
       "99406       0        0  ...                0       0          1             0   \n",
       "113631      0        0  ...                0       0          1             0   \n",
       "117672      0        1  ...                0       0          1             0   \n",
       "126162      0        0  ...                0       0          1             0   \n",
       "139009      0        0  ...                0       0          1             0   \n",
       "147781      0        0  ...                0       0          1             0   \n",
       "149708      0        0  ...                0       0          1             0   \n",
       "157348      0        0  ...                0       0          1             0   \n",
       "165271      0        0  ...                0       0          1             0   \n",
       "199144      0        0  ...                0       0          1             0   \n",
       "218418      0        0  ...                0       0          1             0   \n",
       "219280      0        0  ...                0       0          1             0   \n",
       "220786      0        0  ...                0       0          1             0   \n",
       "255584      0        0  ...                0       0          1             0   \n",
       "\n",
       "       quotes_count mdots_count  brackets_balance  has_phone  is_poll  e_count  \n",
       "0                 0           0                 0          0    False        1  \n",
       "1                 0           0                 9          0    False        1  \n",
       "1070              0           0                 9          0    False        1  \n",
       "1759              0           0                 9          0    False        1  \n",
       "4836              0           0                 9          0    False        1  \n",
       "6826              0           0                 9          0    False        1  \n",
       "8062              0           0                 9          0    False        1  \n",
       "12652             0           0                 9          0    False        1  \n",
       "18474             0           0                 9          0    False        1  \n",
       "19276             0           0                 9          0    False        1  \n",
       "26749             0           0                 9          0    False        1  \n",
       "30506             0           0                 9          0    False        1  \n",
       "32108             0           0                 9          0    False        1  \n",
       "41929             0           0                 9          0    False        1  \n",
       "47045             0           0                 9          0    False        1  \n",
       "51833             0           0                 9          0    False        1  \n",
       "53705             0           0                 9          0    False        1  \n",
       "54208             0           0                 9          0    False        1  \n",
       "57957             0           0                 9          0    False        1  \n",
       "58881             0           0                 9          0    False        1  \n",
       "64069             0           0                 9          0    False        1  \n",
       "83005             0           0                 9          0    False        1  \n",
       "109520            0           0                 9          0    False        1  \n",
       "111763            0           0                 9          0    False        1  \n",
       "112265            0           0                 9          0    False        1  \n",
       "113358            0           0                 9          0    False        1  \n",
       "113648            0           0                 9          0    False        1  \n",
       "114134            0           0                 9          0    False        1  \n",
       "116453            0           0                 9          0    False        1  \n",
       "118080            0           0                 9          0    False        1  \n",
       "...             ...         ...               ...        ...      ...      ...  \n",
       "8                 0           1                 0          0    False        0  \n",
       "262731            0           1                 0          0    False        0  \n",
       "643915            0           1                 0          0    False        0  \n",
       "9                 0           0                 0          0    False        2  \n",
       "6760              0           0                 0          0    False        2  \n",
       "13390             0           0                 0          0    False        2  \n",
       "21137             0           0                 0          0    False        2  \n",
       "26635             0           0                 0          0    False        2  \n",
       "40423             0           0                 0          0    False        2  \n",
       "59812             0           0                 0          0    False        2  \n",
       "71361             0           0                 0          0    False        2  \n",
       "75174             0           0                 0          0    False        2  \n",
       "77053             0           0                 0          0    False        2  \n",
       "81625             0           0                 0          0    False        2  \n",
       "84628             0           0                 0          0    False        2  \n",
       "93824             0           0                 0          0    False        2  \n",
       "99406             0           0                 0          0    False        2  \n",
       "113631            0           0                 0          0    False        2  \n",
       "117672            0           0                 0          0    False        2  \n",
       "126162            0           0                 0          0    False        2  \n",
       "139009            0           0                 0          0    False        2  \n",
       "147781            0           0                 0          0    False        2  \n",
       "149708            0           0                 0          0    False        2  \n",
       "157348            0           0                 0          0    False        2  \n",
       "165271            0           0                 0          0    False        2  \n",
       "199144            0           0                 0          0    False        2  \n",
       "218418            0           0                 0          0    False        2  \n",
       "219280            0           0                 0          0    False        2  \n",
       "220786            0           0                 0          0    False        2  \n",
       "255584            0           0                 0          0    False        2  \n",
       "\n",
       "[200 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = train_data[['metadata_ownerId', 'objectId']].groupby('metadata_ownerId').agg({'objectId': 'count'})\n",
    "stat.rename(columns={'objectId': 'owner_count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.join(stat, how='left', on='metadata_ownerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21620659, 34)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = create_features(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d98f1e308ed2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtrain_texts_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtest_texts_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    }
   ],
   "source": [
    "del test_data\n",
    "del train_data\n",
    "del train_texts_features\n",
    "del test_texts_features\n",
    "#del sub\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 170)               17850     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,451\n",
      "Trainable params: 47,771\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      " - 344s - loss: 0.4054 - acc: 0.8442\n",
      "Epoch 2/30\n",
      " - 325s - loss: 0.4011 - acc: 0.8447\n",
      "Epoch 3/30\n",
      " - 327s - loss: 0.4000 - acc: 0.8447\n",
      "Epoch 4/30\n",
      " - 325s - loss: 0.3994 - acc: 0.8447\n",
      "Epoch 5/30\n",
      " - 322s - loss: 0.3989 - acc: 0.8447\n",
      "Epoch 6/30\n",
      " - 322s - loss: 0.3986 - acc: 0.8447\n",
      "Epoch 7/30\n",
      " - 331s - loss: 0.3983 - acc: 0.8447\n",
      "Epoch 8/30\n",
      " - 332s - loss: 0.3981 - acc: 0.8447\n",
      "Epoch 9/30\n",
      " - 329s - loss: 0.3980 - acc: 0.8447\n",
      "Epoch 10/30\n",
      " - 337s - loss: 0.3978 - acc: 0.8447\n",
      "Epoch 11/30\n",
      " - 317s - loss: 0.3976 - acc: 0.8447\n",
      "Epoch 12/30\n",
      " - 324s - loss: 0.3975 - acc: 0.8447\n",
      "Epoch 13/30\n",
      " - 323s - loss: 0.3974 - acc: 0.8447\n",
      "Epoch 14/30\n",
      " - 325s - loss: 0.3973 - acc: 0.8447\n",
      "Epoch 15/30\n",
      " - 329s - loss: 0.3972 - acc: 0.8447\n",
      "Epoch 16/30\n",
      " - 316s - loss: 0.3971 - acc: 0.8447\n",
      "Epoch 17/30\n",
      " - 317s - loss: 0.3971 - acc: 0.8447\n",
      "Epoch 18/30\n",
      " - 316s - loss: 0.3970 - acc: 0.8447\n",
      "Epoch 19/30\n",
      " - 318s - loss: 0.3970 - acc: 0.8447\n",
      "Epoch 20/30\n",
      " - 318s - loss: 0.3969 - acc: 0.8447\n",
      "Epoch 21/30\n",
      " - 320s - loss: 0.3968 - acc: 0.8447\n",
      "Epoch 22/30\n",
      " - 318s - loss: 0.3968 - acc: 0.8447\n",
      "Epoch 23/30\n",
      " - 317s - loss: 0.3967 - acc: 0.8447\n",
      "Epoch 24/30\n",
      " - 315s - loss: 0.3967 - acc: 0.8447\n",
      "Epoch 25/30\n",
      " - 317s - loss: 0.3966 - acc: 0.8447\n",
      "Epoch 26/30\n",
      " - 314s - loss: 0.3966 - acc: 0.8447\n",
      "Epoch 27/30\n",
      " - 317s - loss: 0.3965 - acc: 0.8447\n",
      "Epoch 28/30\n",
      " - 315s - loss: 0.3965 - acc: 0.8447\n",
      "Epoch 29/30\n",
      " - 323s - loss: 0.3964 - acc: 0.8447\n",
      "Epoch 30/30\n",
      " - 395s - loss: 0.3964 - acc: 0.8448\n",
      "Starting train: 2019-03-15 16:52:35.437321\n",
      "CPU times: user 10h 19min 52s, sys: 1h 16min 7s, total: 11h 36min\n",
      "Wall time: 3h 32min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "model3 = MeanModel([KerasModel({\n",
    "    'epochs': 30,\n",
    "    'verbose': 2,\n",
    "    'n1': 170,\n",
    "    'n2': 170,\n",
    "    'dropout': 0.1,\n",
    "    'emb': 'embedding_keras',\n",
    "}), LgbModel({\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_data_in_leaf': 25,\n",
    "    'lambda_l2': 0.0,\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.35,\n",
    "    'feature_fraction': 1,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'num_boost_round': 1000,\n",
    "    'verbose': 0\n",
    "})], [0.5, 0.5])\n",
    "\n",
    "model3.fit(train)\n",
    "pred3 = model3.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.coefs = [0.5, 0.5]\n",
    "pred3 = model3.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predT = pd.read_pickle(output_path + '/pred').T1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitA3 = predict_to_submit(test, pred3 + predT * 0.2)\n",
    "submitA3.to_csv(output_path + \"/textSubmitA3.csv.gz\", header=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "\n",
    "modelT = KerasModel({\n",
    "    'epochs': 30,\n",
    "    'verbose': 2,\n",
    "    'n1': 170,\n",
    "    'n2': 170,\n",
    "    'n3': 85,\n",
    "    'dropout': 0.15,\n",
    "    'emb': 'embedding',\n",
    "})\n",
    "modelT.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12653881, 0.11429563, 0.17078048, ..., 0.05660952, 0.1017186 ,\n",
       "       0.16263291], dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitA1 = predict_to_submit(test, pred2 + predT * 0.2)\n",
    "submitA1.to_csv(output_path + \"/textSubmitA2.csv.gz\", header=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'T1': predT, 'pred2': pred2, 'pred': pred}).to_pickle(output_path + '/pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 170)               18190     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 170)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 170)               29070     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 170)               680       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 171       \n",
      "=================================================================\n",
      "Total params: 48,791\n",
      "Trainable params: 48,111\n",
      "Non-trainable params: 680\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      " - 353s - loss: 0.4056 - acc: 0.8442\n",
      "Epoch 2/30\n",
      " - 334s - loss: 0.4015 - acc: 0.8447\n",
      "Epoch 3/30\n",
      " - 321s - loss: 0.4001 - acc: 0.8447\n",
      "Epoch 4/30\n",
      " - 330s - loss: 0.3993 - acc: 0.8447\n",
      "Epoch 5/30\n",
      " - 338s - loss: 0.3988 - acc: 0.8447\n",
      "Epoch 6/30\n",
      " - 322s - loss: 0.3984 - acc: 0.8447\n",
      "Epoch 7/30\n",
      " - 316s - loss: 0.3982 - acc: 0.8447\n",
      "Epoch 8/30\n",
      " - 325s - loss: 0.3980 - acc: 0.8447\n",
      "Epoch 9/30\n",
      " - 317s - loss: 0.3978 - acc: 0.8447\n",
      "Epoch 10/30\n",
      " - 324s - loss: 0.3976 - acc: 0.8447\n",
      "Epoch 11/30\n",
      " - 361s - loss: 0.3974 - acc: 0.8447\n",
      "Epoch 12/30\n",
      " - 473s - loss: 0.3973 - acc: 0.8447\n",
      "Epoch 13/30\n",
      " - 320s - loss: 0.3972 - acc: 0.8447\n",
      "Epoch 14/30\n",
      " - 329s - loss: 0.3971 - acc: 0.8447\n",
      "Epoch 15/30\n",
      " - 327s - loss: 0.3970 - acc: 0.8447\n",
      "Epoch 16/30\n",
      " - 382s - loss: 0.3969 - acc: 0.8447\n",
      "Epoch 17/30\n",
      " - 334s - loss: 0.3969 - acc: 0.8447\n",
      "Epoch 18/30\n",
      " - 342s - loss: 0.3968 - acc: 0.8448\n",
      "Epoch 19/30\n",
      " - 350s - loss: 0.3967 - acc: 0.8447\n",
      "Epoch 20/30\n",
      " - 344s - loss: 0.3967 - acc: 0.8448\n",
      "Epoch 21/30\n",
      " - 367s - loss: 0.3966 - acc: 0.8447\n",
      "Epoch 22/30\n",
      " - 399s - loss: 0.3966 - acc: 0.8447\n",
      "Epoch 23/30\n",
      " - 480s - loss: 0.3965 - acc: 0.8448\n",
      "Epoch 24/30\n",
      " - 408s - loss: 0.3965 - acc: 0.8448\n",
      "Epoch 25/30\n",
      " - 328s - loss: 0.3964 - acc: 0.8448\n",
      "Epoch 26/30\n",
      " - 392s - loss: 0.3964 - acc: 0.8448\n",
      "Epoch 27/30\n",
      " - 398s - loss: 0.3963 - acc: 0.8448\n",
      "Epoch 28/30\n",
      " - 349s - loss: 0.3963 - acc: 0.8448\n",
      "Epoch 29/30\n",
      " - 339s - loss: 0.3962 - acc: 0.8448\n",
      "Epoch 30/30\n",
      " - 316s - loss: 0.3962 - acc: 0.8448\n",
      "Starting train: 2019-03-14 15:35:17.684911\n",
      "CPU times: user 9h 53min 35s, sys: 1h 21min 17s, total: 11h 14min 52s\n",
      "Wall time: 4h 8min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seed_everything(341)\n",
    "'''\n",
    "KerasModel({\n",
    "    'epochs': 30,\n",
    "    'verbose': 2,\n",
    "    'n1': 170,\n",
    "    'n2': 170,\n",
    "    'n3': 85,\n",
    "    'dropout': 0.15,\n",
    "    'emb': 'embedding',\n",
    "}), \n",
    "'''\n",
    "model = MeanModel([KerasModel({\n",
    "    'epochs': 30,\n",
    "    'verbose': 2,\n",
    "    'n1': 170,\n",
    "    'n2': 170,\n",
    "    'dropout': 0.1,\n",
    "    'emb': 'embedding_keras',\n",
    "}), LgbModel({\n",
    "    'boosting_type': 'gbdt',\n",
    "    'min_data_in_leaf': 25,\n",
    "    'lambda_l2': 0.0,\n",
    "    'num_leaves': 30,\n",
    "    'learning_rate': 0.35,\n",
    "    'feature_fraction': 1,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'num_boost_round': 1000,\n",
    "    'verbose': 0\n",
    "})], [0.5, 0.5])\n",
    "\n",
    "model.fit(train)\n",
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = predict_to_submit(test, pred)\n",
    "submit.to_csv(output_path + \"/textSubmit1.csv.gz\", header=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "      <th>count</th>\n",
       "      <th>relative_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>66422</td>\n",
       "      <td>0.318806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>43664</td>\n",
       "      <td>0.209574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>27742</td>\n",
       "      <td>0.133154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6431</td>\n",
       "      <td>0.030867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>913</td>\n",
       "      <td>0.004382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   len  count  relative_count\n",
       "0    2  66422        0.318806\n",
       "1    3  43664        0.209574\n",
       "2    4  27742        0.133154\n",
       "3    8   6431        0.030867\n",
       "4   16    913        0.004382"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_stat = defaultdict(int)\n",
    "for r in submit:\n",
    "    lens_stat[len(r)] += 1\n",
    "lens_stat = pd.DataFrame([(k, v) for k, v in lens_stat.items()], columns=['len', 'count'])\n",
    "lens_stat['relative_count'] = lens_stat['count'] / lens_stat['count'].sum()\n",
    "lens_stat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_index</th>\n",
       "      <th>lang</th>\n",
       "      <th>instanceId_userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>uz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>sr</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>it</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>fr</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>et</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>hy</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>ro</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>ky</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>uk</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>ms</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>mk</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>tg</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>bg</td>\n",
       "      <td>1613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>12783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12</td>\n",
       "      <td>ru</td>\n",
       "      <td>184691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lang_index     lang  instanceId_userId\n",
       "0           16       uz                  1\n",
       "1           13       sr                  2\n",
       "2            7       it                  2\n",
       "3            5       fr                 14\n",
       "4            4       et                 15\n",
       "5            6       hy                 15\n",
       "6           11       ro                 24\n",
       "7            8       ky                 35\n",
       "8           15       uk                 43\n",
       "9           10       ms                 45\n",
       "10           3       en                 45\n",
       "11           9       mk                 50\n",
       "12           1       be                259\n",
       "13          14       tg                363\n",
       "14           2       bg               1613\n",
       "15           0  Unknown              12783\n",
       "16          12       ru             184691"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_stat = pd.concat((train_data, test_data), sort=False)[['lang', 'instanceId_userId']].head(200000) \\\n",
    "    .groupby('lang').count().reset_index().sort_values(['instanceId_userId']).reset_index()\n",
    "lang_stat.rename(columns={'index': 'lang_index'}, inplace=True)\n",
    "lang_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''audit_timestamp = train_data.audit_timestamp.apply(lambda x: int(x) // 1000)\n",
    "plt.figure(figsize=(35,15))\n",
    "plt.hist(audit_timestamp, 1800, color='red', alpha=0.5, stacked=True)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''plt.figure(figsize=(35,15))\n",
    "plt.hist(audit_timestamp[(audit_timestamp % (3600*24) > 7*3600) & (audit_timestamp % (3600*24) < 20*3600)], 1800, color='red', alpha=0.5, stacked=True)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_day(ts):\n",
    "    ts = int(ts) // 1000\n",
    "    x = ts % 3600*24\n",
    "    return x > 7*3600 and x < 20*3600\n",
    "\n",
    "train_data['is_day'] = train_data.metadata_createdAt.apply(is_day)\n",
    "test_data['is_day'] = test_data.metadata_createdAt.apply(is_day)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
