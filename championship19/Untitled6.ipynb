{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%run cv.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_twits = pd.read_csv('/Users/tyamgin/Downloads/positive.csv', sep=';', header=None).iloc[:,3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_twits = pd.read_csv('/Users/tyamgin/Downloads/negative.csv', sep=';', header=None).iloc[:,3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "def clear_text(text):\n",
    "    text = text.lower().replace(\"ё\", \"е\")\n",
    "    text = re.sub('((www\\.)|(https?://)|(ok\\.ru/))[^\\s]+', '', text)\n",
    "    text = re.sub('@[^\\s]+', '', text)\n",
    "    text = re.sub('[^a-zA-Zа-яА-Я]+', ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.strip()\n",
    "    \n",
    "def stem_text(text):\n",
    "    text = clear_text(text)\n",
    "    return ' '.join(russian_stemmer.stem(word) for word in text.split() if word)\n",
    "    \n",
    "text = 'Василий https://some-link Геннадий @some_username Виталий ok.ru/group/343434'\n",
    "assert stem_text(text) == 'васил геннад витал'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_positive = [stem_text(txt) for txt in positive_twits]\n",
    "stemmed_negative = [stem_text(txt) for txt in negative_twits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    }
   ],
   "source": [
    "test_texts = parquet.read_table(input_path + '/texts/textsTest/').to_pandas().text.values\n",
    "train_texts = parquet.read_table(input_path + '/texts/textsTrain').to_pandas().text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = []\n",
    "stemmed_negative = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test done\n"
     ]
    }
   ],
   "source": [
    "stemmed_test = [stem_text(txt) for txt in test_texts]\n",
    "print('test done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train done\n"
     ]
    }
   ],
   "source": [
    "stemmed_train = [stem_text(txt) for txt in train_texts]\n",
    "print('train done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'stems': stemmed_test}).to_pickle(output_path + '/stemmed_test')\n",
    "pd.DataFrame({'stems': stemmed_train}).to_pickle(output_path + '/stemmed_train')\n",
    "pd.DataFrame({'stems': stemmed_positive}).to_pickle(output_path + '/stemmed_positive')\n",
    "pd.DataFrame({'stems': stemmed_negative}).to_pickle(output_path + '/stemmed_negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['хот я и школот но повер у нас то же сам d обществ профилир предмет тип',\n",
       "       'да все так он немн похож на нег но мо мальчик все равн лучш d',\n",
       "       'rt ну ты идиотк я испуга за теб', ...,\n",
       "       'что происход со мно когд в эфир proactivefm звуч мо любим песн dctalk music',\n",
       "       'любим я подар теб эт звезд им как звезд перевод подмышк',\n",
       "       'посмотр непытайтесьпокинутьомск сегодн в вавилон в я там тож ест'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(output_path + '/stemmed_positive').stems.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4193784x667084 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 156437619 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,1), min_df=2)\n",
    "matrix = vectorizer.fit_transform(#stemmed_positive + stemmed_negative + stemmed_test + stemmed_train)\n",
    "    np.concatenate((pd.read_pickle(output_path + '/stemmed_positive').stems.values,\n",
    "                    pd.read_pickle(output_path + '/stemmed_negative').stems.values,\n",
    "                    pd.read_pickle(output_path + '/stemmed_test').stems.values,\n",
    "                    pd.read_pickle(output_path + '/stemmed_train').stems.values)))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz(output_path + \"/pos_neg_sparse_1_2_.npz\", matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = sparse.load_npz(output_path + \"/pos_neg_sparse_2_2.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = matrix.astype(np.float32)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41min 53s, sys: 17min 27s, total: 59min 21s\n",
      "Wall time: 1h 13min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "svder = TruncatedSVD(n_components=80, n_iter=10)\n",
    "feats = svder.fit_transform(matrix)\n",
    "pd.DataFrame(feats[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4193784, 80)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4193784, 12061647)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4305707"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_twits.shape[0] + negative_twits.shape[0] + 3410916 + 667957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4193784"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3410916 + 667957 + positive_twits.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = positive_twits.shape[0]\n",
    "test_texts_shape_0 = parquet.read_table(input_path + '/texts/textsTest').to_pandas().shape[0]\n",
    "pd.DataFrame({'embeddings': list(feats[ss:ss+test_texts_shape_0])}).to_pickle(output_path + '/test__80__svd')\n",
    "pd.DataFrame({'embeddings': list(feats[ss+test_texts_shape_0:])}).to_pickle(output_path + '/train__80__svd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'label': np.concatenate((np.repeat(1, positive_twits.shape[0]), \n",
    "                                              np.repeat(0, negative_twits.shape[0])))})\n",
    "for i in range(feats.shape[1]):\n",
    "    data['emb%d' % i] = feats[0:data.shape[0],i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, random_state=231, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=444, solver='lbfgs', max_iter=1000).fit(train.drop('label', 1), train.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba(test.drop('label', 1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6518189352660072"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test.label, pred > 0.5) # 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6127246116136769"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test.label, pred > 0.5) # 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6731383025622035"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test.label, pred > 0.5) # 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8093600663034086"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test.label, pred > 0.5) # 250 new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=444, solver='lbfgs', max_iter=1000).fit(data.drop('label', 1), data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_proba = model.predict_proba(feats[data.shape[0]:,:])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_test_len = len(pd.read_pickle(output_path + '/stemmed_test').stems.values)\n",
    "pd.DataFrame({'positivity': res_proba[0:stemmed_test_len]}).to_pickle(output_path + '/positivity_test2')\n",
    "pd.DataFrame({'positivity': res_proba[stemmed_test_len:]}).to_pickle(output_path + '/positivity_train2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
